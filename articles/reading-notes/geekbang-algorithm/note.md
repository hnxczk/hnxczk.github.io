# 极客时间：数据结构与算法之美
## 01 Why
- 通关大厂面试
- 掌握数据结构和算法，不管对于阅读框架源码，还是理解其背后的设计思想都是非常有用的
- 有追求，不想被行业淘汰，就不能只会写凑合的代码，性能好坏是好代码其中一个要求
## 02 How
抓住重点
### 定义
- 广义
    数据结构就是指一组数据的储存结构，算法就是操作数据的一组方法
- 狭义
    某些著名的数据结构和算法，比如队列、堆、栈、二分查找等等。利用这些前人的智慧可以高效地帮助我们解决实际开发问题

数据结构是为算法服务的，算法要作用于特定的数据结构上。二者无法孤立。

### 学习重点

- 掌握复杂度分析
- 十个数据结构
    数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树
- 十个算法
    递归、排序、二分查找、搜索、哈希、贪心、分治、回溯、动态规划、字符串匹配

要学习算法和数据结构的来历、自身特点、适应解决的问题以及实际的应用场景

### 学习技巧
- 边学边练，适度刷题
- 多问，多思考，多互动
- 打怪升级学习法
- 知识需要沉淀，不要企图一下子掌握所有

## 03 复杂度分析（上）

复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半

### 事后统计法

跑一遍代码，通过统计、监控来得到算法执行的时间和占用的内存大小。

缺点
- 测试结果非常依赖测试环境
- 搜数据规模的影响很大

### 大 O 复杂度表示法
所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比

T(n) = O(f(n))

T(n) 表示代码执行时间
n 表示数据规模
f(n) 表示所有代码的执行次数总和
O 表示代码的执行时间 T(n) 与 f(n) 成正比

大 O 时间复杂度实际上并不表示代码的真正执行时间，而是表示**代码执行时间随数据规模增长的变化趋势**，也被称为**渐进时间复杂度**，简称**时间复杂度**

### 时间复杂度分析

#### 1. 只关注循环执行次数最多的代码

由于大 O 浮渣度分析只是表示一种变化趋势，会忽略掉公式里的常量、低阶、系数，只记录最大阶的量级。因此分析时间复杂度的时候，只关注循环执行次数最多的代码就可以了。

#### 2. 加法法则：总的复杂度等于量级最大的那段代码的复杂度
如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))).
#### 3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积
 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)*g(n)).
### 常见时间复杂度分析实例
- 多项式量级
    - 常数阶 O(1)
    - 对数阶 O(logn)
    - 线性阶 O(n)
    - 线性对数阶 O(nlogn)
    - 平方阶 O(n^2)、立方阶 O(n^3)...
- 非多项式量级
    - 指数阶 O(2^n)
    - 阶乘阶 O(n!)

当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。
#### 多项式量级
##### 1. O(1)
一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万的代码也是 O(1)
##### 2.  O(log n)、O(n log n)
```
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
```
设 x 为执行次数， 则 2 的 x 次方等于 n, 因此 x = log2n。
采用大 O 变价复杂度的时候，对于对数阶的时间复杂度常忽略对数的底，统一表示为 O(logn)
##### 3. O(m+n)、O(m*n)
代码的复杂度由两个数据的规模来决定.

加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。

### 空间复杂度分析

空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。

## 03 复杂度分析（下）

### 复杂度分析的 4 个概念
1. 最坏情况时间复杂度：代码在最理想情况下执行的时间复杂度。
2. 最好情况时间复杂度：代码在最坏情况下执行的时间复杂度。
3. 平均时间复杂度：用代码在所有情况下执行的次数的加权平均值表示。
4. 均摊时间复杂度：在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是高级别复杂度且发生具有时序关系时，可以将个别高级别复杂度均摊到低级别复杂度上。基本上均摊结果就等于低级别复杂度。

### 平均情况时间复杂度

查找变量 x 是否在 容量为 n 的数组中

我们知道，要查找的变量 x，要么在数组里，要么就不在数组里。假设在数组中与不在数组中的概率都为 1/2。另外，要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n。所以，根据概率乘法法则，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)。

这就是概率论里的加权平均数，也称为期望值，所以平均时间复杂度全称是加权平均时间复杂度或者期望时间复杂度

### 均摊时间复杂度

对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。

这种复杂度分析的方法称为**摊还分析**，通过摊还分析得到的时间复杂度我们起了一个名字，叫均摊时间复杂度。

在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。

均摊时间复杂度就是一种特殊的平均时间复杂度

### 如何分析平均、均摊时间复杂度？
1. 平均时间复杂度
代码在不同情况下复杂度出现量级差别，则用代码所有可能情况下执行次数的加权平均值表示。
2. 均摊时间复杂度
两个条件满足时使用：1）代码在绝大多数情况下是低级别复杂度，只有极少数情况是高级别复杂度；2）低级别和高级别复杂度出现具有时序规律。均摊结果一般都等于低级别复杂度。

## 04 数据结构与算法学习书单

入门：大话数据结构、算法图解

面试：剑指offer

经典：算法

## 05 数组

### 定义

**数组是一种_线性表_数据结构。它用一组_连续的内存空间_来存储一组具有_相同类型_的数据。**

### 随机访问

数组支持随机访问，根据下标随机访问的时间复杂度是 O(1)。

#### 如何实现根据下标随机访问数组元素？

通过寻址公式，计算出该元素存储的内存地址：
```
a[i]_address = base_address + i * data_type_size
```

### 低效的“插入”和“删除”

#### 插入：
若有一元素想往 int[n] 的第 k 个位置插入数据，需要在 k-n 的位置往后移。

最好情况时间复杂度 O(1)
最坏情况复杂度为 O(n)
平均负责度为 O(n)

如果数组中的数据不是有序的，也就是无规律的情况下，可以直接把第 k 个位置上的数据移到最后，然后将插入的数据直接放在第 k 个位置上。这样时间复杂度就将为 O（1）了。

#### 删除：
与插入类似，为了保持内存的连续性。

最好情况时间复杂度 O(1)
最坏情况复杂度为 O(n)
平均负责度为 O(n)

提高效率：将多次删除操作中集中在一起执行，可以先记录已经删除的数据，但是不进行数据迁移，而仅仅是记录，当发现没有更多空间存储时，再执行真正的删除操作。这也是 JVM 标记清除垃圾回收算法的核心思想。

### 警惕数组的访问越界问题

数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。 不同的语言对数组访问越界的处理方式不同，即便是同一种语言，不同的编译器处理的方式也不同。

### 容器与数组的选择

1. 存储基本数据类型，或者更关注性能可以使用数组
2. 数据大小已知，并且对数据的操作简单，可以使用数组
3. 多维数组的时候，数组更加直观
4. 业务开发，使用容器足够，开发框架，追求性能，首先数组

### 为什么大多数数组从 0 开始编号

1. 数组的根据下标访问元素是根据计算公式来计算内存偏移，从 0 开始更合理
2. 习惯问题

### JVM 标记清除算法
在标记阶段会标记所有的可访问的对象，在清除阶段会遍历堆，回收那些没有被标记的对象。现在想想，和「如果数组中的数据不是有序的，也就是无规律的情况下，可以直接把第k个位置上的数据移到最后，然后将插入的数据直接放在第k个位置上。」思想类似。

### 二维数组内存寻址

对于 `m * n` 的数组，`a [ i ][ j ] (i < m,j < n)`的地址为：
```
address = base_address + ( i * n + j) * type_size
```

## 06 链表（上）

### 定义

通过指针将一组零散的内存块串联起来就构成了链表。

其中这些内存块称为**节点**，节点中记录链表下个节点地址的指针称为**后继指针**。

两个特殊节点：第一个节点称为**头结点**，最后一个节点称为**尾节点**，尾节点的后继节点是一个**空地址 NULL**

### 分类
1. 单链表 单链表的节点只包含一个存储数据的内存空间和后继指针 next
2. 双向链表 双向链表的节点包含一个存储数据的内存空间以及前驱指针 prev 和后继指针 next
3. 循环链表 尾节点的后继指针指向头节点的链表就是循环链表

### 双向链表的优点
链表遍历的时间复杂度是 O(n),在实际使用中双向链表可以减少链表的遍历操作。

### 链表与数组性能对比
#### 数组
- 随机访问 O(1) 插入删除 O(n)
- 实际使用中由于数组使用的是连续内存空间，可以借助 CPU 的缓存机制预读数组中的数据，因此访问效率更高。
- 数组扩容非常耗时
#### 链表
- 随机访问 O(n) 插入删除 O(1)
- 由于不是连续内存，对 CPU 缓存不太友好。
- 更容易造成内存碎片
- 对于 Java 来说还会导致频繁的垃圾回收。

### 基于链表实现 LRU 缓存淘汰算法

1. 当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。
2. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。
3. 如果此数据没有在缓存链表中，又可以分为两种情况：
    * 如果此时缓存未满，则将此结点直接插入到链表的头部；
    * 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。


## 07 链表（下）

### 写链表代码的技巧

1. 理解指针或引用的含义

    将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。
2. 警惕指针丢失和内存泄漏
    - 插入结点时，一定要注意操作的顺序
    - 删除链表结点时，也一定要记得手动释放内存空间（自动管理内存的语言除外）
3. 利用哨兵简化实现难度

    链表中的“哨兵”节点是解决边界问题的，不参与业务逻辑。如果我们引入“哨兵”节点，则不管链表是否为空，head指针都会指向这个“哨兵”节点。
    
    我们把这种有“哨兵”节点的链表称为带头链表，相反，没有“哨兵”节点的链表就称为不带头链表。
4. 重点留意边界条件处理
    * 如果链表为空时，代码是否能正常工作？
    * 如果链表只包含一个结点时，代码是否能正常工作？
    * 如果链表只包含两个结点时，代码是否能正常工作？
    * 代码逻辑在处理头结点和尾结点的时候，是否能正常工作？
5. 举例画图，辅助思考

6. 多写多练，没有捷径

### 常见链表题

* 单链表反转
* 链表中环的检测
* 两个有序的链表合并
* 删除链表倒数第 n 个结点
* 求链表的中间结点

### tips
- 利用 LeetCode 刷题

    LeetCode上的测试用例往往很全，能测试出特殊情况下的 bug
- 不用太纠结

    在一定时间内实在想不出来就去搜一下答案，没必要一直纠结。有些巧妙的解题思路确实不是很好想出来的。

## 08 栈

### 定义
#### 什么是栈
- 后进者先出，先进者后出，这就是典型的“栈”结构。
- 从栈的操作特性来看，是一种“操作受限”的线性表，只允许在端插入（push）和删除数据（pop）。
#### 为什么需要栈？
- 栈是一种操作受限的数据结构，其操作特性用数组和链表均可实现。
- 但，任何数据结构都是对特定应用场景的抽象，数组和链表虽然使用起来更加灵活，但却暴露了几乎所有的操作，难免会引发错误操作的风险。
- 所以，当某个数据集合只涉及在某端插入和删除数据，且满足后进者先出，先进者后出的操作特性时，我们应该首选栈这种数据结构。
### 实现
- 用数组实现的栈，我们叫作顺序栈
- 用链表实现的栈，我们叫作链式栈

#### 复杂度

不管是顺序栈还是链式栈，入栈、出栈只涉及栈顶个别数据的操作，所以时间复杂度都是 O(1)

在入栈和出栈过程中，只需要一两个临时变量存储空间，所以复杂度是 O(1)

**空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。**

#### 支持动态扩容的顺序栈

根据摊还分析法，每次需要扩容的 push 的复杂度可以均摊到普通的不需要扩容时 push，因此其均摊时间复杂度是 O(1)

### 应用

#### 1.函数调用
操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构，用来存储函数调用时的临时变量。

每进入一个函数，就会将其中的临时变量作为栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。
#### 2.表达式
利用两个栈，其中一个用来保存操作数，另一个用来保存运算符。

我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较，若比运算符栈顶元素优先级高，就将当前运算符压入栈，若比运算符栈顶元素的优先级低或者相同，从运算符栈中取出栈顶运算符，从操作数栈顶取出2个操作数，然后进行计算，把计算完的结果压入操作数栈，继续比较。
#### 3.括号匹配
用栈保存为匹配的左括号，从左到右一次扫描字符串，当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号，如果能匹配上，则继续扫描剩下的字符串。

如果扫描过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。

当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明未匹配的左括号为非法格式。
#### 4.浏览器的前进后退
使用两个栈 A 和 B，浏览过程中把浏览的界面按顺序压入栈 A 中。

点击返回的按钮时，让栈 A 栈顶出栈，出栈的数据压入栈 B 中。

点击前进按钮时， 让栈 B 栈顶出栈，出栈的数据压入栈 A。

栈 A 为空说明无法后退， 栈 B 为空说明无法前进。

### QA
#### 1.为什么函数调用要用“栈”来保存临时变量呢？
函数调用的局部状态之所以用栈来记录是因为这些数据的存活时间满足“后入先出”（LIFO）顺序，而栈的基本操作正好就是支持这种顺序的访问。

函数的调用有完美的嵌套关系——调用者的生命期总是长于被调用者的生命期，并且后者在前者的之内。这样，被调用者的局部信息所占空间的分配总是后于调用者的（后入），而其释放则总是先于调用者的（先出），所以正好可以满足栈的LIFO顺序，选用栈这种数据结构来实现调用栈是一种很自然的选择。

[知乎 RednaxelaFX 的 回答](https://www.zhihu.com/question/34499262/answer/59415153)

#### 2.内存中的堆栈和数据结构堆栈是不是一个概念？
内存中的堆栈和数据结构堆栈不是一个概念，可以说内存中的堆栈是真实存在的物理区，数据结构中的堆栈是抽象的数据存储结构
### LeetCode 
20,155,232,844,224,682,496gi

## 09 队列

### 定义
- 先进先出的就是队列
- 与栈一样也是一个操作受限的线性表数据额结构：队列头部取数据（enqueue），队列尾部插入数据（dequeue）

### 实现
- 用数组实现的队列叫作顺序队列
- 用链表实现的队列叫作链式队列
- 为了避免顺序队列的数据搬移，有了循环队列的解决思路

### 循环队列
当顺序队列的数组空间用完之后（tail 等于数组的大小），新插入的数据插入到数组头部。这样就避免了数据迁移。

循环队列的实现关键是 **确定队空和队满的判断**

- 队空：head 等于 tail
- 队满：（tail + 1）%  n == head

表达式是怎么来的：在一般情况下，我们可以看出来，当队列满时，tail+1=head。但是，有个特殊情况，就是tail=n-1，而head=0时，这时候，tail+1=n，而head=0，所以用(tail+1)%n == n%n == 0。而且，tail+1最大的情况就是 n ，不会大于 n，这样，tail+1 除了最大情况，不然怎么余 n 都是 tail+1 本身，也就是 head。这样，表达式就出现了。

### 阻塞队列和并发队列

- 阻塞队列：在队列基础上增加了阻塞操作。队列为空的时候从堆头取数据被阻塞，队列满了之后插入数据被阻塞
- 并发队列：能保证多线程并发操作时线程安全的队列称为并发队列

### 应用
对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。

### 无锁并发队列
考虑使用CAS实现无锁队列。在入队前，获取tail位置，入队时比较tail是否发生变化，如果否，则允许入队，反之，本次入队失败。出队则是获取head位置，进行cas。

> CAS操作——Compare & Set，或是 Compare & Swap 现在几乎所有的CPU指令都支持CAS的原子操作。
> "原子操作(atomic operation)是不需要synchronized"，这是多线程编程的老生常谈了。 所谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何context switch （切 换到另一个线程）。

## 10 递归

### 递归需要满足的三个条件
- 一个问题的解可以分解为几个四问题的解
- 这个问题已分解后的子问题，除了数据规模一样，求解思路完全一样
- 存在递归终止条件

### 如何编写递归代码

- **写递归代码的关键就是找到如何将大问题分解为小问题的规律，并基于此写出递推公式，然后找到终止条件，最后将他们翻译成代码**

- **编写递归代码的关键是，只要遇到递归，我们就把它抽象成一盒递推公式，不用想一层层的调用用关系，不要试图用人脑分解递归的每个步骤**

### 需要注意的问题

#### 堆栈溢出

由于函数调用会使用栈来保存临时变量，每调用一个函数都会将临时变量封装为栈帧压入内存栈，等函数执行完成后返回再出栈。这样以来当递归求解数据规模很大，调用层级很深，就会出现堆栈溢出的风险。

#### 警惕重复的计算

求解递归的过程中可能会出现重复计算的问题，这时候可以通过散列表等数据结构来保存计算结果。如果已经求解过了就直接返回，不需要重复计算。

#### 注意空间复杂度

由于递归每调用一次就会在内存堆栈中保存一次现场数据，因此计算递归代码的空间复杂的时候需要考虑着些额外内存开销。

### 递归代码改写成飞递归代码

理论上递归代码都可以改写为非递归代码，但是这样会增加实现的复杂度。

如何做？抽象出递推公式、初始值和边界条件，然后用迭代循环实现。

## 11 排序：冒泡，插入，选择

### 如何分析一个排序算法

#### 执行效率
- 最好情况、最坏情况、平均情况时间复杂度
- 时间复杂度的系数、常数、低阶
- 比较次数和交换、移动次数

#### 内存消耗

原地排序：特指空间复杂度是 O(1)的排序算法。

#### 稳定性

经过排序算法的排序之后，如果原来数据中相同元素的前后顺序没有发生改变，这种算法就称为稳定的排序算法，否则称为不稳定的排序算法。

### 冒泡排序

冒泡排序的原理就是比较相邻元素的大小，符合条件则交换相邻元素的位置，否则继续遍历。

```
void bubbleSort(int *array, int n)
{
    if (n <= 1) return;
    
    for (int i = 0; i < n; ++i) {
        bool change = false;
        for (int j = 0; j < n-i-1; ++j) {
            if (array[j] > array[j+1]) {
                int tmp = array[j+1];
                array[j+1] = array[j];
                array[j] = tmp;
                change = true;
            }
        }
        if (!change) break;
    }
}
```
**编码的过程**

1. 由于每次冒泡只能确定一个最值的位置，因此要想全部排序就需要两个 for 循环
2. 外侧循环表示冒泡的次数，因此循环次数与元素个数 n 相同
3. 内侧循环执行冒泡操作，由于每次冒泡能确定一个元素的最终位置，因此第 i 次冒泡需要操作的元素个数是 n-1-i 个。因此内侧循环从 0 开始 执行 n-i-1 次
4. 如果一次冒泡过程中没有改变元素的位置，只表明元素的顺序已经排好，因此可以通过一个标识标识一次冒泡的过程中是否改变元素位置，如果没有更改就直接退出外侧循环。这样实现了冒泡的优化


#### 冒泡排序是否是原地算法
是，空间复杂度是 O(1)

#### 冒泡排序是否是稳定的排序
是，冒泡的过程中只有当相邻元素的大小不同时才会去改变顺序，相同的元素不会改变顺序。

#### 冒泡排序的时间复杂度

最好情况时间复杂度 O(n)
最坏情况时间复杂度 O(n^2)

平均时间复杂度通过有序度和逆序度分析

- 有序度：数组中具有有序关系的元素对的个数
- 逆序度：数组中具有逆序关系的元素对的个数
- 满有序度：完全有序的数组的有序度

```
逆序度 = 满有序度 - 有序度
```

对于 n 个元素的数组，满有序度为 n*(n-1)/2

最坏情况下有序度为 0，则逆序度为 n*(n-1)/2。这时候要将逆序度减为 0，则需要 n*(n-1)/2 次交换。

因此平均情况下需要 n*(n-1)/4 次交换，因此平均情况复杂度为 O(n^2)

### 插入排序

插入排序的原理就是动态的往有序集合中添加数据。将数组分为已排序区和未排序区，不断将未排序区的元素插入到已排序区中。初始的已排序区只有数组的第一个元素，然后不断添加，直到全部排序完成。

```
void insertionSort(int *array, int n)
{
    if (n <= 1) return;
    
    for (int i = 1; i < n; ++i) {
        int val = array[i];
        int j = i-1;
        for (; j >= 0; --j) {
            if (array[j] > val) {
                array[j+1] = array[j];
            } else {
                break;
            }
        }
        array[j+1] = val;
    }
}
```

**编码的过程**

1. 由于需要把数组的所有元素不断插入已排序区，在插入排序区的过程中需要不断比较插入元素与之前已排序区元素的大小，因此需要两个 for 循环
2. 外侧循环用来遍历所有的元素，因此从 0 开始，循环 n 次
3. 内侧循环用来比较已经选中的元素 array[i] 与已排序区的元素比较，从后往前遍历，因此从 i-1 开始，循环 i-1 次
4. 在内侧循环比较已选中元素 array[i] 与已排序元素时，如果已选中元素满足条件（比如上面的 大于）就替换二者位置，相当于把已选中元素插入到当前已排序元素之前，直到不满足条件说明 选中元素插入到了正确的位置，跳出循环。
5. 内侧循环过一次之后，将 选中的元素插入到内循环结束时的位置，由于内循环体结束时 j 是最终插入的前一个位置，因此需要把选中的元素插入到 j+1 的位置上。

#### 插入排序是否是原地算法
是，空间复杂度是 O(1)

#### 插入排序是否是稳定的排序
是，插入的过程中可以将后面出现的元素插入到前面出现元素的后面，这样以来就不会改变之前相同元素的顺序。

#### 插入排序的时间复杂度

最好是时间复杂度为 O(n)
最坏情况时间复杂度为 O(n^2)

有序数组中插入某个元素的平均时间复杂度是 O(n), 而插入排序需要遍历数组的元素，将每个元素都插入到有序区间中，因此其平均时间复杂度为 O(n^2)

### 选择排序

选择排序通过不断遍历未排序的区域，每次都用一个变量记录最小（大）值的位置，找到位置之后在遍历结束后交换最值与第一个未排序元素的位置

```
void selectionSort(int *array, int n)
{
    if (n <= 1) return;
    
    for (int i = 0; i < n; ++i) {
        int index = i;
        for (int j = i+1; j < n; ++j) {
            if (array[j] < array[index]) {
                index = j;
            }
        }
        if (index != i) {
            int tmp = array[i];
            array[i] = array[index];
            array[index] = tmp;
        }
    }
}
```

**实现步骤**

1. 遍历未排序区查找最值需要一个循环，每次遍历完未排序区之后未排序区就发生了变化，因此需要再次遍历直到未排序区消失，于是要有两个循环嵌套
2. 由于每次内侧循环能确定一个最值的位置，因此外循环从 0 开始 遍历 n 次
3. 内侧循环用来遍历当前未排序区，查找到最值的位置，然后在循环结束之后交换未排序区的第一个元素和最值的位置

#### 选择排序是否是原地算法
是，空间复杂度是 O(1)

#### 选择排序是否是稳定的排序
不是，每次选择最值之后就与未排序区第一个位置交换，这就会打乱之前的相同元素的排序，因此不是稳定的排序。

#### 插入排序的时间复杂度

最好是时间复杂度为 O(n)
最坏情况时间复杂度为 O(n^2)
其平均时间复杂度为 O(n^2)

### 插入与冒泡比较

冒泡排序中每次交换相邻元素位置需要的进行的操作比插入排序的数据移动来说更为耗时，因此插入排序一般优于冒泡排序。

### QA 使用链表实现

>对于老师所提课后题，觉得应该有个前提，是否允许修改链表的节点value值，还是只能改变节点的位置。一般而言，考虑只能改变节点位置，冒泡排序相比于数组实现，比较次数一致，但交换时操作更复杂；插入排序，比较次数一致，不需要再有后移操作，找到位置后可以直接插入，但排序完毕后可能需要倒置链表；选择排序比较次数一致，交换操作同样比较麻烦。综上，时间复杂度和空间复杂度并无明显变化，若追求极致性能，冒泡排序的时间复杂度系数会变大，插入排序系数会减小，选择排序无明显变化。

## 12 排序：归并排序，快速排序

### 归并排序

归并排序使用了**分治思想**，将一个大问题分解成小的子问题。而分治算法一般都通过递归来实现。

其思路就是讲一个数组的排序分为两个子数组的排序，两个子数组排序完成后按大小顺序合并两个子数组就等到了排好序的整个数组。

```
void merge_sort_recursive(int arr[], int reg[], int start, int end)
{
    // 递归基础
    if (start >= end) return;
    
    // 求中间点，len >> 1 相当于 len / 2
    int len = end - start, mid = (len >> 1) + start;
    // 分别归并排序
    int start1 = start, end1 = mid;
    int start2 = mid + 1, end2 = end;

    merge_sort_recursive(arr, reg, start1, end1);
    merge_sort_recursive(arr, reg, start2, end2);
    
    // 合并排序好的数组
    // k 用来标识已经合并好数组中的最后的位置
    int k = start;
    while (start1 <= end1 && start2 <= end2) {
        reg[k++] = arr[start1] <= arr[start2] ? arr[start1++] : arr[start2++];
    }
    // 此时说明前半段数据多于后半部分
    while (start1 <= end1) {
        reg[k++] = arr[start1++];
    }
    // 此时说明后半段数据多于前半部分
    while (start2 <= end2) {
        reg[k++] = arr[start2++];
    }
    
    // 将辅助数组中数据拷贝到原数组
    for (k = start; k <= end; k++) {
        arr[k] = reg[k];
    }
}

void merge_sort(int arr[], int len)
{
    int reg[len];
    merge_sort_recursive(arr, reg, 0, len-1);
}
```

#### 思路

- 由于需要进行递归，而且在合并子数组的时候需要额外的内存空间来存放排好序的数组，因此需要辅助函数 merge_sort_recursive，然后声明一个大小与原数组相同的辅助数组来存放排好序的元素
- 然后编写递归函数，找到递推公式和递推基础
    - 递推公式

    ```
    merge_sort(start...end) = merge_sort(start...mid), merge_sort(mid+1...end)
    ```

    - 递推基础

    ```
    start >= end
    ```

- 编写合并子数组的代码
    - 使用两个变量 start1、start2 指向两个子数组中尚未合并的第一个元素的下标
    - 使用变量 k 指向合并好的数组中的位置
    - 每次从子数组中取最小的元素放入合并好的数组之中，并移动各个指示变量
    - 第一个循环过后将子数组中剩余元素拼接到排好序的数组中
    - 将辅助数组中数据拷贝到原数组

#### 归并排序性能

##### 归并排序是稳定的排序算法

在合并子数组的过程中先将左侧子数组放入合并好的数组中就可以实现稳定的排序算法

##### 归并排序的时间复杂度是 O(nlogn)

**不仅递归求解的问题可以写成递推公式，递归代码的时间复杂度也可以写成递推公式**

递归代码时间复杂度递推公式

```
T(a) = T(b) + T(c) + K
```

归并排序的时间复杂度计算公式

```
T(1) = C；   n=1 时，只需要常量级的执行时间，所以表示为 C。
T(n) = 2*T(n/2) + n； n>1
```

不断将 n 代入

```
T(n) = 2*T(n/2) + n
     = 2*(2*T(n/4) + n/2) + n       = 4*T(n/4) + 2*n
     = 4*(2*T(n/8) + n/4) + 2*n     = 8*T(n/8) + 3*n
     = 8*(2*T(n/16) + n/8) + 3*n    = 16*T(n/16) + 4*n
     ......
     = 2^k * T(n/2^k) + k * n
     ......
```

由于 T(1) = C 则 n/2^k = 1 时 T(n/2^k) = C 此时 k = log2n, 代入可得到
T(n)=Cn+nlog2n

##### 归并排序的空间复杂度是 O(n)

归并排序不是原地排序算法，需要额外的空间来合并数据。

### 快速排序

快速排序也是使用了分治思想，基本思路就是先找到一个枢轴点（分区点）pivot，然后遍历数据，将小于 pivot 的放于左侧，大于的放于右侧。然后分别对枢轴点左右两侧区间的数组进行排序，直到区间缩小到 1 。这时候整个数组就是有序的了。

递归代码
```
void quick_sort_recursive(int arr[], int start, int end)
{
    if (start >= end) return;
    
    int pivot = partition_1(arr, start, end);
    
    quick_sort_recursive(arr, start, pivot - 1);
    quick_sort_recursive(arr, pivot + 1, end);
}

void quick_sort(int arr[], int len)
{
    quick_sort_recursive(arr, 0, len - 1);
}
```
查找枢轴代码

```
void swap(int *a, int *b)
{
    int tmp = *a;
    *a = *b;
    *b = tmp;
}

// 方法 1
int partition(int arr[], int low, int high)
{
    // pivot 记录枢轴大小，以起始位置数据大小为枢轴
    int pivot = arr[low];
    
    while (low < high) {
        // 从右侧开始查找，直到查找到小于枢轴的位置
        while (arr[high] >= pivot && low < high) {
            --high;
        }
        // 将右侧小于枢轴大小的值交换到左侧
        swap(&arr[low], &arr[high]);
        // 从左侧开始查找，直到查找到大于枢轴的位置
        while (arr[low] <= pivot && low < high) {
            ++low;
        }
        // 将左侧大于枢轴的值交换到右侧
        swap(&arr[low], &arr[high]);
    }
    // 跳出循环说明 low 和 high 重合，此时所有小于枢轴的值位于枢轴值的左侧，大于的位于右侧
    
    return low;
}

// 方法 2
int partition_1(int arr[], int low, int high)
{
    // 取最右侧值为枢轴，i 来作为游标分割比枢轴值小的值和比枢轴大的值
    int pivot = arr[high], i = low;
    
    // 通过 j 来遍历未处理的数据
    for (int j = low; j < high; ++j) {
        // 未处理数据小于枢轴，则将其放到已处理区的最后，然后已处理区的大小 +1
        if (arr[j] < pivot) {
            swap(&arr[i], &arr[j]);
            ++i;
        }
    }
    // 位于 i 位置之前的都是小于枢轴的，i 和它之后的都是大于枢轴的，交换 i 位置和选定的枢轴的值
    swap(&arr[i], &arr[high]);
    
    return i;
}
```

#### 思路

- 首先需要查找枢轴点
    1. 思路一
        1. 首先以起始点作为枢轴，使用变量 pivot 记录枢轴点的值
        2. 分别使用变量 low 和 high 记录还未处理的分区，大于 low 小于 high 的区间是未处理的区间，其他都是处理过的区间，处理过的区间能保证左侧的全都小于枢轴的值，右侧全都大于枢轴的值
        3. 从右侧开始查找，直到查找到小于枢轴值的位置
        4. 将右侧小于枢轴的值交换到左侧小于枢轴的区间，枢轴值现在就在右侧
        5. 从左侧开始查找，直到找到大于枢轴值的位置
        6. 将左侧大于枢轴的值交换到右侧，枢轴值现在位于左侧
        7. 就这样不停交换枢轴的位置直到未处理的区间全部处理完成，此时所有小于枢轴的值位于枢轴值的左侧，大于的位于右侧
    2. 思路二
        1. 取最右侧值为枢轴，i 为游标标记小于枢轴值的区域（小区）， 小于等于 i 位置的区域都是小于枢轴的值
        2. 通过 j 遍历未处理的数据
        3. 处理数据，如果其小于枢轴则放到 小区 最后面，也就是 i 指示的位置，然后 i 后移，表示 小区 增加
        4. 退出循环表示所有的数据都已经处理， 小于 i 指示位置之前的都是小于枢轴的值，大于 i 的位置除了最后的枢轴，都大于枢轴的值
        5. 交换枢轴与 i 指向值的位置，此时所有小于枢轴的值位于枢轴值的左侧，大于的位于右侧
- 编写递归函数
    - 递推函数

    ```
    quick_sort(start...end) = quick_sort(start...pivot-1), quick_sort(pivot+1...end)
    ```
    - 递归基础

    ```
    start >= end
    ```

#### 快排的性能

##### 快速排序不是稳定的排序算法

上面的所有思路都会在分区的过程涉及交换操作，这就会改变相邻元素的顺序，因此不稳定。

##### 快速排序时间复杂度是 O(nlogn)
如果每次分区操作，都能正好把数组分成大小接近相等的两个小区间，那快排的时间复杂度递推求解公式跟归并是相同的。所以，快排的时间复杂度也是 O(nlogn)。

当然不是每次选择枢轴都是正好位于中间，当枢轴两端分区极度不平衡的时候,需要进行将近 n 次分区，此时快排的时间复杂度会退化为 O(n^2)。

##### 快速排序空间复杂度是 O(1)

上面的解题思路中没有涉及到额外内存空间，因此是原地排序算法。

### QA : O(n) 时间复杂度内求无序数组中的第 K 大元素

利用快排的分区的思路

- 选择某个元素作为枢轴，对数组进行原地分区，p 表示枢轴所在的位置
- 由于是查找第k大的值，因此左侧区域放大值，右侧区域放小值
    1. 若 p + 1 > K ，则 说明第 K 大的元素位于右侧侧小值区，继续在右侧侧区间查找
    2. 若 p + 1 < K 则说明第 K 大的元素位于左侧大值区， 继续再左侧区间查找
    3. 若 p + 1 = K 说明 p 所在位置对应的值就是要查找的值

```
int partition(int arr[], int start, int end)
{
    int pivot = arr[end], i = start;
    for (int j = start; j < end; ++j) {
        if (arr[j] > pivot) {
            swap(&arr[j], &arr[i]);
            ++i;
        }
    }
    swap(&arr[end], &arr[i]);
    return i;
}

int KthLargest(int arr[], int n, int K)
{
    if (K <= 0) return -1;
    
    int pivot = -1, start = 0, end = n - 1;
    while (pivot + 1 != K) {
        pivot = partition(arr, start, end);
        if (pivot + 1 > K) {
            end = pivot - 1;
        } else if (pivot + 1 < K) {
            start = pivot + 1;
        }
    }
    return arr[pivot];
}
```

## 13 线性排序：桶排序，计数排序，基数排序

### 桶排序

#### 思路

将要排序的数据分到几个有序的桶里，对每个桶里的数据再单独进行排序。排序完成之后再把每个桶里的数据按照顺序依次取出，组成新的序列就是有序的了。

#### 时间复杂度

1. 划分成 m 个桶，每个桶里的元素个数就是 k = n/m 
2. 每个桶内使用快速排序，则每个桶时间复杂度就是 O(klogk)
3. 所有的桶的时间复杂度就是 O(m * klogk),也就是 O(m * (n/m)log(n/m)),继续简化 O(nlog(n/m))
4. m 趋近于 n 的时候其趋近于 O(n)

#### 是稳定排序
桶内排序方法是稳定排序的时候就是稳定的排序
#### 不是原地排序
需要用额外的空间来作为桶，因此不是原地排序，空间复杂度是 O(n + k), k 是桶的个数

#### 使用条件

1. 需要排序的数据需要很容易划分成 m 个桶，并且桶之间有着大小顺序
2. 每个桶中的数据分布要比较均匀

#### 适用情况

桶排序比较适合用在外部排序中。也就是数据存储在外部磁盘且数据量大，但内存有限无法将整个数据全部加载到内存

**需求描述：**

有10GB的订单数据，需按订单金额（假设金额都是正整数）进行排序，但内存有限，仅几百MB

**解决思路：**
- 扫描一遍文件，看订单金额所处数据范围，比如1元-10万元，那么就分100个桶。
- 第一个桶存储金额1-1000元之内的订单，第二个桶存1001-2000元之内的订单，依次类推。
- 每个桶对应一个文件，并按照金额范围的大小顺序编号命名（00，01，02，…，99）。
- 将100个小文件依次放入内存并用快排排序。
- 所有文件排好序后，只需按照文件编号从小到大依次读取每个小文件并写到大文件中即可。
- 
**注意点：**

若单个文件无法全部载入内存，则针对该文件继续按照前面的思路进行处理即可。

### 计数排序

#### 思路

计数其实与桶排序非常类似，只是桶的粒度不同。当要排序的n个数据所处范围并不大时，比如最大值为k，则分成k个桶，这时每个桶内的数据值都是相同的。

```
void counting_sort(int arr[], int n)
{
    if (n <= 1) return;
    
    // 获取最大值
    int max = arr[0];
    for (int i = 1; i < n; ++i) {
        if (max < arr[i]) {
            max = arr[i];
        }
    }
    
    // 申请 max + 1 个空间 初始化为 0，记录元素的出现次数
    int *counts = malloc(sizeof(int) * (max + 1));
    for (int i = 0; i <= max; ++i) {
        counts[i] = 0;
    }
    
    // 计算从 0 到 max 大小的这些元素出现的次数
    for (int i = 0; i < n; ++i) {
        int val = arr[i];
        counts[val]++;
    }
    
    // 累加出现次数，遍历过后每个位置都记录了该小于等于该值的出现次数
    for (int i = 1; i <= max; ++i) {
        counts[i] = counts[i] + counts[i - 1];
    }
    
    // 临时数组
    int *tmp = malloc(sizeof(int) * n);
    // 遍历原数组
    for (int i = n - 1; i >= 0 ; --i) {
        // 取到当前位置元素
        int num = arr[i];
        // 由于 counts[num] 记录就是小于等于 num 大小元素的出现次数，因此将其减一就能获取到排序完成之后该大小元素最后一个位置
        int index = counts[num] - 1;
        // 将该元素放到对应位置
        tmp[index] = num;
        // 由于上面 num 大小的元素有一个排好了顺序，这里将 counts 中 num 对应的次数减一
        counts[num]--;
    }
    
    // 将结果拷贝给原数组
    for (int i = 0; i < n; ++i) {
        arr[i] = tmp[i];
    }
    
    free(counts);
    free(tmp);
}
```

**代码实现**

1. 查找需要排序的数组中的最大值 max
2. 申请 max + 1 大小的数组 counts，用于记录每个大小的元素出现次数，全都初始化为 0
3. 遍历原数组，记录每个大小元素出现的次数
4. 累加每个元素出现的次数，比如 counts 中 k 这个位置记录了 **小于等于** k 大小元素出现的次数
5. 遍历原数组，由于 counts[num] 记录就是 **小于等于** num 大小元素的出现次数，因此将其减一就能获取到排序完成之后该大小元素最后一个位置
6. 将 num 放到 临时数组对应的位置
7. 放好一个 num 大小的元素后将 counts[num] 的值减去 1 
8. 将临时数组的元素拷贝到原数组

#### 使用条件
1. 只能用在数据范围不大的场景中，若数据范围k比要排序的数据n大很多，就不适合用计数排序；
2. 计数排序只能给非负整数排序，其他类型需要在不改变相对大小情况下，转换为非负整数；
3. 比如如果考试成绩精确到小数后一位，就需要将所有分数乘以10，转换为整数。

#### 时间复杂度
O(n + k), k 是数据的范围

#### 是稳定排序
取决于往临时数组 tmp 中添加数据的先后，上面代码中从原数组后面往前遍历，这时原数组中相同大小的元素靠后的放在临时数组 tmp 靠后的位置，这样就保证了计数排序是稳定的排序。如果此时是从前往后遍历就不是稳定的排序了，正好与原数组中的顺序相反

#### 不是原地排序
需要用额外的空间来作为桶，因此不是原地排序，空间复杂度是 O(n + k), k 是数据的范围

### 基数排序
#### 算法原理（以排序10万个手机号为例来说明）
1. 比较两个手机号码a，b的大小，如果在前面几位中a已经比b大了，那后面几位就不用看了。
2. 借助稳定排序算法的思想，可以先按照最后一位来排序手机号码，然后再按照倒数第二位来重新排序，以此类推，最后按照第一个位重新排序。
3. 经过11次排序后，手机号码就变为有序的了。
4. 每次排序有序数据范围较小，可以使用桶排序或计数排序来完成。
#### 使用条件
1. 要求数据可以分割独立的“位”来比较；
2. 位之间由递进关系，如果a数据的高位比b数据大，那么剩下的地位就不用比较了；
3. 每一位的数据范围不能太大，要可以用线性排序，否则基数排序的时间复杂度无法做到O(n)。

#### 时间复杂度
O(n * k), k 是数据的维度（比如上面的例子中就是手机号的位数 11）

#### 是稳定排序
是稳定排序，如果不是稳定排序就实现不了多维度的排序

#### 不是原地排序
需要用额外的空间来作为桶，因此不是原地排序，空间复杂度是 O(n + k), k 是数据的维度

### QA 对于一组包含大小写的字符进行排序，使小写的排在大写的前面。若字符中不仅有大小写还有数字的话就将数字放中间

用两个指针a、b：a指针从头开始往后遍历，遇到大写字母就停下，b从后往前遍历，遇到小写字母就停下，交换a、b指针对应的元素；重复如上过程，直到a、b指针相交。

对于小写字母放前面，数字放中间，大写字母放后面，可以先将数据分为小写字母和非小写字母两大类，进行如上交换后再在非小写字母区间内分为数字和大写字母做同样处理

