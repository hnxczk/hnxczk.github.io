# 极客时间：数据结构与算法之美
## 01 Why
- 通关大厂面试
- 掌握数据结构和算法，不管对于阅读框架源码，还是理解其背后的设计思想都是非常有用的
- 有追求，不想被行业淘汰，就不能只会写凑合的代码，性能好坏是好代码其中一个要求
## 02 How
抓住重点
### 定义
- 广义
    数据结构就是指一组数据的储存结构，算法就是操作数据的一组方法
- 狭义
    某些著名的数据结构和算法，比如队列、堆、栈、二分查找等等。利用这些前人的智慧可以高效地帮助我们解决实际开发问题

数据结构是为算法服务的，算法要作用于特定的数据结构上。二者无法孤立。

### 学习重点

- 掌握复杂度分析
- 十个数据结构
    数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树
- 十个算法
    递归、排序、二分查找、搜索、哈希、贪心、分治、回溯、动态规划、字符串匹配

要学习算法和数据结构的来历、自身特点、适应解决的问题以及实际的应用场景

### 学习技巧
- 边学边练，适度刷题
- 多问，多思考，多互动
- 打怪升级学习法
- 知识需要沉淀，不要企图一下子掌握所有

## 03 复杂度分析（上）

复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半

### 事后统计法

跑一遍代码，通过统计、监控来得到算法执行的时间和占用的内存大小。

缺点
- 测试结果非常依赖测试环境
- 搜数据规模的影响很大

### 大 O 复杂度表示法
所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比

T(n) = O(f(n))

T(n) 表示代码执行时间
n 表示数据规模
f(n) 表示所有代码的执行次数总和
O 表示代码的执行时间 T(n) 与 f(n) 成正比

大 O 时间复杂度实际上并不表示代码的真正执行时间，而是表示**代码执行时间随数据规模增长的变化趋势**，也被称为**渐进时间复杂度**，简称**时间复杂度**

### 时间复杂度分析

#### 1. 只关注循环执行次数最多的代码

由于大 O 浮渣度分析只是表示一种变化趋势，会忽略掉公式里的常量、低阶、系数，只记录最大阶的量级。因此分析时间复杂度的时候，只关注循环执行次数最多的代码就可以了。

#### 2. 加法法则：总的复杂度等于量级最大的那段代码的复杂度
如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))).
#### 3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积
 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)*g(n)).
### 常见时间复杂度分析实例
- 多项式量级
    - 常数阶 O(1)
    - 对数阶 O(logn)
    - 线性阶 O(n)
    - 线性对数阶 O(nlogn)
    - 平方阶 O(n^2)、立方阶 O(n^3)...
- 非多项式量级
    - 指数阶 O(2^n)
    - 阶乘阶 O(n!)

当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。
#### 多项式量级
##### 1. O(1)
一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万的代码也是 O(1)
##### 2.  O(log n)、O(n log n)
```
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
```
设 x 为执行次数， 则 2 的 x 次方等于 n, 因此 x = log2n。
采用大 O 变价复杂度的时候，对于对数阶的时间复杂度常忽略对数的底，统一表示为 O(logn)
##### 3. O(m+n)、O(m*n)
代码的复杂度由两个数据的规模来决定.

加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。

### 空间复杂度分析

空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。

## 03 复杂度分析（下）

### 复杂度分析的 4 个概念
1. 最坏情况时间复杂度：代码在最理想情况下执行的时间复杂度。
2. 最好情况时间复杂度：代码在最坏情况下执行的时间复杂度。
3. 平均时间复杂度：用代码在所有情况下执行的次数的加权平均值表示。
4. 均摊时间复杂度：在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是高级别复杂度且发生具有时序关系时，可以将个别高级别复杂度均摊到低级别复杂度上。基本上均摊结果就等于低级别复杂度。

### 平均情况时间复杂度

查找变量 x 是否在 容量为 n 的数组中

我们知道，要查找的变量 x，要么在数组里，要么就不在数组里。假设在数组中与不在数组中的概率都为 1/2。另外，要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n。所以，根据概率乘法法则，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)。

这就是概率论里的加权平均数，也称为期望值，所以平均时间复杂度全称是加权平均时间复杂度或者期望时间复杂度

### 均摊时间复杂度

对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。

这种复杂度分析的方法称为**摊还分析**，通过摊还分析得到的时间复杂度我们起了一个名字，叫均摊时间复杂度。

在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。

均摊时间复杂度就是一种特殊的平均时间复杂度

### 如何分析平均、均摊时间复杂度？
1. 平均时间复杂度
代码在不同情况下复杂度出现量级差别，则用代码所有可能情况下执行次数的加权平均值表示。
2. 均摊时间复杂度
两个条件满足时使用：1）代码在绝大多数情况下是低级别复杂度，只有极少数情况是高级别复杂度；2）低级别和高级别复杂度出现具有时序规律。均摊结果一般都等于低级别复杂度。

## 04 数据结构与算法学习书单

入门：大话数据结构、算法图解

面试：剑指offer

经典：算法

## 05 数组

### 定义

**数组是一种_线性表_数据结构。它用一组_连续的内存空间_来存储一组具有_相同类型_的数据。**

### 随机访问

数组支持随机访问，根据下标随机访问的时间复杂度是 O(1)。

#### 如何实现根据下标随机访问数组元素？

通过寻址公式，计算出该元素存储的内存地址：
```
a[i]_address = base_address + i * data_type_size
```

### 低效的“插入”和“删除”

#### 插入：
若有一元素想往 int[n] 的第 k 个位置插入数据，需要在 k-n 的位置往后移。

最好情况时间复杂度 O(1)
最坏情况复杂度为 O(n)
平均负责度为 O(n)

如果数组中的数据不是有序的，也就是无规律的情况下，可以直接把第 k 个位置上的数据移到最后，然后将插入的数据直接放在第 k 个位置上。这样时间复杂度就将为 O（1）了。

#### 删除：
与插入类似，为了保持内存的连续性。

最好情况时间复杂度 O(1)
最坏情况复杂度为 O(n)
平均负责度为 O(n)

提高效率：将多次删除操作中集中在一起执行，可以先记录已经删除的数据，但是不进行数据迁移，而仅仅是记录，当发现没有更多空间存储时，再执行真正的删除操作。这也是 JVM 标记清除垃圾回收算法的核心思想。

### 警惕数组的访问越界问题

数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。 不同的语言对数组访问越界的处理方式不同，即便是同一种语言，不同的编译器处理的方式也不同。

### 容器与数组的选择

1. 存储基本数据类型，或者更关注性能可以使用数组
2. 数据大小已知，并且对数据的操作简单，可以使用数组
3. 多维数组的时候，数组更加直观
4. 业务开发，使用容器足够，开发框架，追求性能，首先数组

### 为什么大多数数组从 0 开始编号

1. 数组的根据下标访问元素是根据计算公式来计算内存偏移，从 0 开始更合理
2. 习惯问题

### JVM 标记清除算法
在标记阶段会标记所有的可访问的对象，在清除阶段会遍历堆，回收那些没有被标记的对象。现在想想，和「如果数组中的数据不是有序的，也就是无规律的情况下，可以直接把第k个位置上的数据移到最后，然后将插入的数据直接放在第k个位置上。」思想类似。

### 二维数组内存寻址

对于 `m * n` 的数组，`a [ i ][ j ] (i < m,j < n)`的地址为：
```
address = base_address + ( i * n + j) * type_size
```

## 06 链表（上）

### 定义

通过指针将一组零散的内存块串联起来就构成了链表。

其中这些内存块称为**节点**，节点中记录链表下个节点地址的指针称为**后继指针**。

两个特殊节点：第一个节点称为**头结点**，最后一个节点称为**尾节点**，尾节点的后继节点是一个**空地址 NULL**

### 分类
1. 单链表 单链表的节点只包含一个存储数据的内存空间和后继指针 next
2. 双向链表 双向链表的节点包含一个存储数据的内存空间以及前驱指针 prev 和后继指针 next
3. 循环链表 尾节点的后继指针指向头节点的链表就是循环链表

### 双向链表的优点
链表遍历的时间复杂度是 O(n),在实际使用中双向链表可以减少链表的遍历操作。

### 链表与数组性能对比
#### 数组
- 随机访问 O(1) 插入删除 O(n)
- 实际使用中由于数组使用的是连续内存空间，可以借助 CPU 的缓存机制预读数组中的数据，因此访问效率更高。
- 数组扩容非常耗时
#### 链表
- 随机访问 O(n) 插入删除 O(1)
- 由于不是连续内存，对 CPU 缓存不太友好。
- 更容易造成内存碎片
- 对于 Java 来说还会导致频繁的垃圾回收。

### 基于链表实现 LRU 缓存淘汰算法

1. 当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。
2. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。
3. 如果此数据没有在缓存链表中，又可以分为两种情况：
    * 如果此时缓存未满，则将此结点直接插入到链表的头部；
    * 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。


## 07 链表（下）

### 写链表代码的技巧

1. 理解指针或引用的含义

    将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。
2. 警惕指针丢失和内存泄漏
    - 插入结点时，一定要注意操作的顺序
    - 删除链表结点时，也一定要记得手动释放内存空间（自动管理内存的语言除外）
3. 利用哨兵简化实现难度

    链表中的“哨兵”节点是解决边界问题的，不参与业务逻辑。如果我们引入“哨兵”节点，则不管链表是否为空，head指针都会指向这个“哨兵”节点。
    
    我们把这种有“哨兵”节点的链表称为带头链表，相反，没有“哨兵”节点的链表就称为不带头链表。
4. 重点留意边界条件处理
    * 如果链表为空时，代码是否能正常工作？
    * 如果链表只包含一个结点时，代码是否能正常工作？
    * 如果链表只包含两个结点时，代码是否能正常工作？
    * 代码逻辑在处理头结点和尾结点的时候，是否能正常工作？
5. 举例画图，辅助思考

6. 多写多练，没有捷径

### 常见链表题

* 单链表反转
* 链表中环的检测
* 两个有序的链表合并
* 删除链表倒数第 n 个结点
* 求链表的中间结点

### tips
- 利用 LeetCode 刷题

    LeetCode上的测试用例往往很全，能测试出特殊情况下的 bug
- 不用太纠结

    在一定时间内实在想不出来就去搜一下答案，没必要一直纠结。有些巧妙的解题思路确实不是很好想出来的。

## 08 栈

### 定义
#### 什么是栈
- 后进者先出，先进者后出，这就是典型的“栈”结构。
- 从栈的操作特性来看，是一种“操作受限”的线性表，只允许在端插入（push）和删除数据（pop）。
#### 为什么需要栈？
- 栈是一种操作受限的数据结构，其操作特性用数组和链表均可实现。
- 但，任何数据结构都是对特定应用场景的抽象，数组和链表虽然使用起来更加灵活，但却暴露了几乎所有的操作，难免会引发错误操作的风险。
- 所以，当某个数据集合只涉及在某端插入和删除数据，且满足后进者先出，先进者后出的操作特性时，我们应该首选栈这种数据结构。
### 实现
- 用数组实现的栈，我们叫作顺序栈
- 用链表实现的栈，我们叫作链式栈

#### 复杂度

不管是顺序栈还是链式栈，入栈、出栈只涉及栈顶个别数据的操作，所以时间复杂度都是 O(1)

在入栈和出栈过程中，只需要一两个临时变量存储空间，所以复杂度是 O(1)

**空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。**

#### 支持动态扩容的顺序栈

根据摊还分析法，每次需要扩容的 push 的复杂度可以均摊到普通的不需要扩容时 push，因此其均摊时间复杂度是 O(1)

### 应用

#### 1.函数调用
操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构，用来存储函数调用时的临时变量。

每进入一个函数，就会将其中的临时变量作为栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。
#### 2.表达式
利用两个栈，其中一个用来保存操作数，另一个用来保存运算符。

我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较，若比运算符栈顶元素优先级高，就将当前运算符压入栈，若比运算符栈顶元素的优先级低或者相同，从运算符栈中取出栈顶运算符，从操作数栈顶取出2个操作数，然后进行计算，把计算完的结果压入操作数栈，继续比较。
#### 3.括号匹配
用栈保存为匹配的左括号，从左到右一次扫描字符串，当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号，如果能匹配上，则继续扫描剩下的字符串。

如果扫描过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。

当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明未匹配的左括号为非法格式。
#### 4.浏览器的前进后退
使用两个栈 A 和 B，浏览过程中把浏览的界面按顺序压入栈 A 中。

点击返回的按钮时，让栈 A 栈顶出栈，出栈的数据压入栈 B 中。

点击前进按钮时， 让栈 B 栈顶出栈，出栈的数据压入栈 A。

栈 A 为空说明无法后退， 栈 B 为空说明无法前进。

### QA
#### 1.为什么函数调用要用“栈”来保存临时变量呢？
函数调用的局部状态之所以用栈来记录是因为这些数据的存活时间满足“后入先出”（LIFO）顺序，而栈的基本操作正好就是支持这种顺序的访问。

函数的调用有完美的嵌套关系——调用者的生命期总是长于被调用者的生命期，并且后者在前者的之内。这样，被调用者的局部信息所占空间的分配总是后于调用者的（后入），而其释放则总是先于调用者的（先出），所以正好可以满足栈的LIFO顺序，选用栈这种数据结构来实现调用栈是一种很自然的选择。

[知乎 RednaxelaFX 的 回答](https://www.zhihu.com/question/34499262/answer/59415153)

#### 2.内存中的堆栈和数据结构堆栈是不是一个概念？
内存中的堆栈和数据结构堆栈不是一个概念，可以说内存中的堆栈是真实存在的物理区，数据结构中的堆栈是抽象的数据存储结构
### LeetCode 
20,155,232,844,224,682,496gi

## 09 队列

### 定义
- 先进先出的就是队列
- 与栈一样也是一个操作受限的线性表数据额结构：队列头部取数据（enqueue），队列尾部插入数据（dequeue）

### 实现
- 用数组实现的队列叫作顺序队列
- 用链表实现的队列叫作链式队列
- 为了避免顺序队列的数据搬移，有了循环队列的解决思路

### 循环队列
当顺序队列的数组空间用完之后（tail 等于数组的大小），新插入的数据插入到数组头部。这样就避免了数据迁移。

循环队列的实现关键是 **确定队空和队满的判断**

- 队空：head 等于 tail
- 队满：（tail + 1）%  n == head

表达式是怎么来的：在一般情况下，我们可以看出来，当队列满时，tail+1=head。但是，有个特殊情况，就是tail=n-1，而head=0时，这时候，tail+1=n，而head=0，所以用(tail+1)%n == n%n == 0。而且，tail+1最大的情况就是 n ，不会大于 n，这样，tail+1 除了最大情况，不然怎么余 n 都是 tail+1 本身，也就是 head。这样，表达式就出现了。

### 阻塞队列和并发队列

- 阻塞队列：在队列基础上增加了阻塞操作。队列为空的时候从堆头取数据被阻塞，队列满了之后插入数据被阻塞
- 并发队列：能保证多线程并发操作时线程安全的队列称为并发队列

### 应用
对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。

### 无锁并发队列
考虑使用CAS实现无锁队列。在入队前，获取tail位置，入队时比较tail是否发生变化，如果否，则允许入队，反之，本次入队失败。出队则是获取head位置，进行cas。

> CAS操作——Compare & Set，或是 Compare & Swap 现在几乎所有的CPU指令都支持CAS的原子操作。
> "原子操作(atomic operation)是不需要synchronized"，这是多线程编程的老生常谈了。 所谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何context switch （切 换到另一个线程）。

## 10 递归

### 递归需要满足的三个条件
- 一个问题的解可以分解为几个四问题的解
- 这个问题已分解后的子问题，除了数据规模一样，求解思路完全一样
- 存在递归终止条件

### 如何编写递归代码

- **写递归代码的关键就是找到如何将大问题分解为小问题的规律，并基于此写出递推公式，然后找到终止条件，最后将他们翻译成代码**

- **编写递归代码的关键是，只要遇到递归，我们就把它抽象成一盒递推公式，不用想一层层的调用用关系，不要试图用人脑分解递归的每个步骤**

### 需要注意的问题

#### 堆栈溢出

由于函数调用会使用栈来保存临时变量，每调用一个函数都会将临时变量封装为栈帧压入内存栈，等函数执行完成后返回再出栈。这样以来当递归求解数据规模很大，调用层级很深，就会出现堆栈溢出的风险。

#### 警惕重复的计算

求解递归的过程中可能会出现重复计算的问题，这时候可以通过散列表等数据结构来保存计算结果。如果已经求解过了就直接返回，不需要重复计算。

#### 注意空间复杂度

由于递归每调用一次就会在内存堆栈中保存一次现场数据，因此计算递归代码的空间复杂的时候需要考虑着些额外内存开销。

### 递归代码改写成飞递归代码

理论上递归代码都可以改写为非递归代码，但是这样会增加实现的复杂度。

如何做？抽象出递推公式、初始值和边界条件，然后用迭代循环实现。

## 11 排序：冒泡，插入，选择

### 如何分析一个排序算法

#### 执行效率
- 最好情况、最坏情况、平均情况时间复杂度
- 时间复杂度的系数、常数、低阶
- 比较次数和交换、移动次数

#### 内存消耗

原地排序：特指空间复杂度是 O(1)的排序算法。

#### 稳定性

经过排序算法的排序之后，如果原来数据中相同元素的前后顺序没有发生改变，这种算法就称为稳定的排序算法，否则称为不稳定的排序算法。

### 冒泡排序

冒泡排序的原理就是比较相邻元素的大小，符合条件则交换相邻元素的位置，否则继续遍历。

```
void bubbleSort(int *array, int n)
{
    if (n <= 1) return;
    
    for (int i = 0; i < n; ++i) {
        bool change = false;
        for (int j = 0; j < n-i-1; ++j) {
            if (array[j] > array[j+1]) {
                int tmp = array[j+1];
                array[j+1] = array[j];
                array[j] = tmp;
                change = true;
            }
        }
        if (!change) break;
    }
}
```
**编码的过程**

1. 由于每次冒泡只能确定一个最值的位置，因此要想全部排序就需要两个 for 循环
2. 外侧循环表示冒泡的次数，因此循环次数与元素个数 n 相同
3. 内侧循环执行冒泡操作，由于每次冒泡能确定一个元素的最终位置，因此第 i 次冒泡需要操作的元素个数是 n-1-i 个。因此内侧循环从 0 开始 执行 n-i-1 次
4. 如果一次冒泡过程中没有改变元素的位置，只表明元素的顺序已经排好，因此可以通过一个标识标识一次冒泡的过程中是否改变元素位置，如果没有更改就直接退出外侧循环。这样实现了冒泡的优化


#### 冒泡排序是否是原地算法
是，空间复杂度是 O(1)

#### 冒泡排序是否是稳定的排序
是，冒泡的过程中只有当相邻元素的大小不同时才会去改变顺序，相同的元素不会改变顺序。

#### 冒泡排序的时间复杂度

最好情况时间复杂度 O(n)
最坏情况时间复杂度 O(n^2)

平均时间复杂度通过有序度和逆序度分析

- 有序度：数组中具有有序关系的元素对的个数
- 逆序度：数组中具有逆序关系的元素对的个数
- 满有序度：完全有序的数组的有序度

```
逆序度 = 满有序度 - 有序度
```

对于 n 个元素的数组，满有序度为 n*(n-1)/2

最坏情况下有序度为 0，则逆序度为 n*(n-1)/2。这时候要将逆序度减为 0，则需要 n*(n-1)/2 次交换。

因此平均情况下需要 n*(n-1)/4 次交换，因此平均情况复杂度为 O(n^2)

### 插入排序

插入排序的原理就是动态的往有序集合中添加数据。将数组分为已排序区和未排序区，不断将未排序区的元素插入到已排序区中。初始的已排序区只有数组的第一个元素，然后不断添加，直到全部排序完成。

```
void insertionSort(int *array, int n)
{
    if (n <= 1) return;
    
    for (int i = 1; i < n; ++i) {
        int val = array[i];
        int j = i-1;
        for (; j >= 0; --j) {
            if (array[j] > val) {
                array[j+1] = array[j];
            } else {
                break;
            }
        }
        array[j+1] = val;
    }
}
```

**编码的过程**

1. 由于需要把数组的所有元素不断插入已排序区，在插入排序区的过程中需要不断比较插入元素与之前已排序区元素的大小，因此需要两个 for 循环
2. 外侧循环用来遍历所有的元素，因此从 0 开始，循环 n 次
3. 内侧循环用来比较已经选中的元素 array[i] 与已排序区的元素比较，从后往前遍历，因此从 i-1 开始，循环 i-1 次
4. 在内侧循环比较已选中元素 array[i] 与已排序元素时，如果已选中元素满足条件（比如上面的 大于）就替换二者位置，相当于把已选中元素插入到当前已排序元素之前，直到不满足条件说明 选中元素插入到了正确的位置，跳出循环。
5. 内侧循环过一次之后，将 选中的元素插入到内循环结束时的位置，由于内循环体结束时 j 是最终插入的前一个位置，因此需要把选中的元素插入到 j+1 的位置上。

#### 插入排序是否是原地算法
是，空间复杂度是 O(1)

#### 插入排序是否是稳定的排序
是，插入的过程中可以将后面出现的元素插入到前面出现元素的后面，这样以来就不会改变之前相同元素的顺序。

#### 插入排序的时间复杂度

最好是时间复杂度为 O(n)
最坏情况时间复杂度为 O(n^2)

有序数组中插入某个元素的平均时间复杂度是 O(n), 而插入排序需要遍历数组的元素，将每个元素都插入到有序区间中，因此其平均时间复杂度为 O(n^2)

### 选择排序

选择排序通过不断遍历未排序的区域，每次都用一个变量记录最小（大）值的位置，找到位置之后在遍历结束后交换最值与第一个未排序元素的位置

```
void selectionSort(int *array, int n)
{
    if (n <= 1) return;
    
    for (int i = 0; i < n; ++i) {
        int index = i;
        for (int j = i+1; j < n; ++j) {
            if (array[j] < array[index]) {
                index = j;
            }
        }
        if (index != i) {
            int tmp = array[i];
            array[i] = array[index];
            array[index] = tmp;
        }
    }
}
```

**实现步骤**

1. 遍历未排序区查找最值需要一个循环，每次遍历完未排序区之后未排序区就发生了变化，因此需要再次遍历直到未排序区消失，于是要有两个循环嵌套
2. 由于每次内侧循环能确定一个最值的位置，因此外循环从 0 开始 遍历 n 次
3. 内侧循环用来遍历当前未排序区，查找到最值的位置，然后在循环结束之后交换未排序区的第一个元素和最值的位置

#### 选择排序是否是原地算法
是，空间复杂度是 O(1)

#### 选择排序是否是稳定的排序
不是，每次选择最值之后就与未排序区第一个位置交换，这就会打乱之前的相同元素的排序，因此不是稳定的排序。

#### 插入排序的时间复杂度

最好是时间复杂度为 O(n)
最坏情况时间复杂度为 O(n^2)
其平均时间复杂度为 O(n^2)

### 插入与冒泡比较

冒泡排序中每次交换相邻元素位置需要的进行的操作比插入排序的数据移动来说更为耗时，因此插入排序一般优于冒泡排序。

### QA 使用链表实现

>对于老师所提课后题，觉得应该有个前提，是否允许修改链表的节点value值，还是只能改变节点的位置。一般而言，考虑只能改变节点位置，冒泡排序相比于数组实现，比较次数一致，但交换时操作更复杂；插入排序，比较次数一致，不需要再有后移操作，找到位置后可以直接插入，但排序完毕后可能需要倒置链表；选择排序比较次数一致，交换操作同样比较麻烦。综上，时间复杂度和空间复杂度并无明显变化，若追求极致性能，冒泡排序的时间复杂度系数会变大，插入排序系数会减小，选择排序无明显变化。

## 12 排序：归并排序，快速排序

### 归并排序

归并排序使用了**分治思想**，将一个大问题分解成小的子问题。而分治算法一般都通过递归来实现。

其思路就是讲一个数组的排序分为两个子数组的排序，两个子数组排序完成后按大小顺序合并两个子数组就等到了排好序的整个数组。

```
void merge_sort_recursive(int arr[], int reg[], int start, int end)
{
    // 递归基础
    if (start >= end) return;
    
    // 求中间点，len >> 1 相当于 len / 2
    int len = end - start, mid = (len >> 1) + start;
    // 分别归并排序
    int start1 = start, end1 = mid;
    int start2 = mid + 1, end2 = end;

    merge_sort_recursive(arr, reg, start1, end1);
    merge_sort_recursive(arr, reg, start2, end2);
    
    // 合并排序好的数组
    // k 用来标识已经合并好数组中的最后的位置
    int k = start;
    while (start1 <= end1 && start2 <= end2) {
        reg[k++] = arr[start1] <= arr[start2] ? arr[start1++] : arr[start2++];
    }
    // 此时说明前半段数据多于后半部分
    while (start1 <= end1) {
        reg[k++] = arr[start1++];
    }
    // 此时说明后半段数据多于前半部分
    while (start2 <= end2) {
        reg[k++] = arr[start2++];
    }
    
    // 将辅助数组中数据拷贝到原数组
    for (k = start; k <= end; k++) {
        arr[k] = reg[k];
    }
}

void merge_sort(int arr[], int len)
{
    int reg[len];
    merge_sort_recursive(arr, reg, 0, len-1);
}
```

#### 思路

- 由于需要进行递归，而且在合并子数组的时候需要额外的内存空间来存放排好序的数组，因此需要辅助函数 merge_sort_recursive，然后声明一个大小与原数组相同的辅助数组来存放排好序的元素
- 然后编写递归函数，找到递推公式和递推基础
    - 递推公式

    ```
    merge_sort(start...end) = merge_sort(start...mid), merge_sort(mid+1...end)
    ```

    - 递推基础

    ```
    start >= end
    ```

- 编写合并子数组的代码
    - 使用两个变量 start1、start2 指向两个子数组中尚未合并的第一个元素的下标
    - 使用变量 k 指向合并好的数组中的位置
    - 每次从子数组中取最小的元素放入合并好的数组之中，并移动各个指示变量
    - 第一个循环过后将子数组中剩余元素拼接到排好序的数组中
    - 将辅助数组中数据拷贝到原数组

#### 归并排序性能

##### 归并排序是稳定的排序算法

在合并子数组的过程中先将左侧子数组放入合并好的数组中就可以实现稳定的排序算法

##### 归并排序的时间复杂度是 O(nlogn)

**不仅递归求解的问题可以写成递推公式，递归代码的时间复杂度也可以写成递推公式**

递归代码时间复杂度递推公式

```
T(a) = T(b) + T(c) + K
```

归并排序的时间复杂度计算公式

```
T(1) = C；   n=1 时，只需要常量级的执行时间，所以表示为 C。
T(n) = 2*T(n/2) + n； n>1
```

不断将 n 代入

```
T(n) = 2*T(n/2) + n
     = 2*(2*T(n/4) + n/2) + n       = 4*T(n/4) + 2*n
     = 4*(2*T(n/8) + n/4) + 2*n     = 8*T(n/8) + 3*n
     = 8*(2*T(n/16) + n/8) + 3*n    = 16*T(n/16) + 4*n
     ......
     = 2^k * T(n/2^k) + k * n
     ......
```

由于 T(1) = C 则 n/2^k = 1 时 T(n/2^k) = C 此时 k = log2n, 代入可得到
T(n)=Cn+nlog2n

##### 归并排序的空间复杂度是 O(n)

归并排序不是原地排序算法，需要额外的空间来合并数据。

### 快速排序

快速排序也是使用了分治思想，基本思路就是先找到一个枢轴点（分区点）pivot，然后遍历数据，将小于 pivot 的放于左侧，大于的放于右侧。然后分别对枢轴点左右两侧区间的数组进行排序，直到区间缩小到 1 。这时候整个数组就是有序的了。

递归代码
```
void quick_sort_recursive(int arr[], int start, int end)
{
    if (start >= end) return;
    
    int pivot = partition_1(arr, start, end);
    
    quick_sort_recursive(arr, start, pivot - 1);
    quick_sort_recursive(arr, pivot + 1, end);
}

void quick_sort(int arr[], int len)
{
    quick_sort_recursive(arr, 0, len - 1);
}
```
查找枢轴代码

```
void swap(int *a, int *b)
{
    int tmp = *a;
    *a = *b;
    *b = tmp;
}

// 方法 1
int partition(int arr[], int low, int high)
{
    // pivot 记录枢轴大小，以起始位置数据大小为枢轴
    int pivot = arr[low];
    
    while (low < high) {
        // 从右侧开始查找，直到查找到小于枢轴的位置
        while (arr[high] >= pivot && low < high) {
            --high;
        }
        // 将右侧小于枢轴大小的值交换到左侧
        swap(&arr[low], &arr[high]);
        // 从左侧开始查找，直到查找到大于枢轴的位置
        while (arr[low] <= pivot && low < high) {
            ++low;
        }
        // 将左侧大于枢轴的值交换到右侧
        swap(&arr[low], &arr[high]);
    }
    // 跳出循环说明 low 和 high 重合，此时所有小于枢轴的值位于枢轴值的左侧，大于的位于右侧
    
    return low;
}

// 方法 2
int partition_1(int arr[], int low, int high)
{
    // 取最右侧值为枢轴，i 来作为游标分割比枢轴值小的值和比枢轴大的值
    int pivot = arr[high], i = low;
    
    // 通过 j 来遍历未处理的数据
    for (int j = low; j < high; ++j) {
        // 未处理数据小于枢轴，则将其放到已处理区的最后，然后已处理区的大小 +1
        if (arr[j] < pivot) {
            swap(&arr[i], &arr[j]);
            ++i;
        }
    }
    // 位于 i 位置之前的都是小于枢轴的，i 和它之后的都是大于枢轴的，交换 i 位置和选定的枢轴的值
    swap(&arr[i], &arr[high]);
    
    return i;
}
```

#### 思路

- 首先需要查找枢轴点
    1. 思路一
        1. 首先以起始点作为枢轴，使用变量 pivot 记录枢轴点的值
        2. 分别使用变量 low 和 high 记录还未处理的分区，大于 low 小于 high 的区间是未处理的区间，其他都是处理过的区间，处理过的区间能保证左侧的全都小于枢轴的值，右侧全都大于枢轴的值
        3. 从右侧开始查找，直到查找到小于枢轴值的位置
        4. 将右侧小于枢轴的值交换到左侧小于枢轴的区间，枢轴值现在就在右侧
        5. 从左侧开始查找，直到找到大于枢轴值的位置
        6. 将左侧大于枢轴的值交换到右侧，枢轴值现在位于左侧
        7. 就这样不停交换枢轴的位置直到未处理的区间全部处理完成，此时所有小于枢轴的值位于枢轴值的左侧，大于的位于右侧
    2. 思路二
        1. 取最右侧值为枢轴，i 为游标标记小于枢轴值的区域（小区）， 小于等于 i 位置的区域都是小于枢轴的值
        2. 通过 j 遍历未处理的数据
        3. 处理数据，如果其小于枢轴则放到 小区 最后面，也就是 i 指示的位置，然后 i 后移，表示 小区 增加
        4. 退出循环表示所有的数据都已经处理， 小于 i 指示位置之前的都是小于枢轴的值，大于 i 的位置除了最后的枢轴，都大于枢轴的值
        5. 交换枢轴与 i 指向值的位置，此时所有小于枢轴的值位于枢轴值的左侧，大于的位于右侧
- 编写递归函数
    - 递推函数

    ```
    quick_sort(start...end) = quick_sort(start...pivot-1), quick_sort(pivot+1...end)
    ```
    - 递归基础

    ```
    start >= end
    ```

#### 快排的性能

##### 快速排序不是稳定的排序算法

上面的所有思路都会在分区的过程涉及交换操作，这就会改变相邻元素的顺序，因此不稳定。

##### 快速排序时间复杂度是 O(nlogn)
如果每次分区操作，都能正好把数组分成大小接近相等的两个小区间，那快排的时间复杂度递推求解公式跟归并是相同的。所以，快排的时间复杂度也是 O(nlogn)。

当然不是每次选择枢轴都是正好位于中间，当枢轴两端分区极度不平衡的时候,需要进行将近 n 次分区，此时快排的时间复杂度会退化为 O(n^2)。

##### 快速排序空间复杂度是 O(1)

上面的解题思路中没有涉及到额外内存空间，因此是原地排序算法。

### QA : O(n) 时间复杂度内求无序数组中的第 K 大元素

利用快排的分区的思路

- 选择某个元素作为枢轴，对数组进行原地分区，p 表示枢轴所在的位置
- 由于是查找第k大的值，因此左侧区域放大值，右侧区域放小值
    1. 若 p + 1 > K ，则 说明第 K 大的元素位于右侧侧小值区，继续在右侧侧区间查找
    2. 若 p + 1 < K 则说明第 K 大的元素位于左侧大值区， 继续再左侧区间查找
    3. 若 p + 1 = K 说明 p 所在位置对应的值就是要查找的值

```
int partition(int arr[], int start, int end)
{
    int pivot = arr[end], i = start;
    for (int j = start; j < end; ++j) {
        if (arr[j] > pivot) {
            swap(&arr[j], &arr[i]);
            ++i;
        }
    }
    swap(&arr[end], &arr[i]);
    return i;
}

int KthLargest(int arr[], int n, int K)
{
    if (K <= 0) return -1;
    
    int pivot = -1, start = 0, end = n - 1;
    while (pivot + 1 != K) {
        pivot = partition(arr, start, end);
        if (pivot + 1 > K) {
            end = pivot - 1;
        } else if (pivot + 1 < K) {
            start = pivot + 1;
        }
    }
    return arr[pivot];
}
```

## 13 线性排序：桶排序，计数排序，基数排序

### 桶排序

#### 思路

将要排序的数据分到几个有序的桶里，对每个桶里的数据再单独进行排序。排序完成之后再把每个桶里的数据按照顺序依次取出，组成新的序列就是有序的了。

#### 时间复杂度

1. 划分成 m 个桶，每个桶里的元素个数就是 k = n/m 
2. 每个桶内使用快速排序，则每个桶时间复杂度就是 O(klogk)
3. 所有的桶的时间复杂度就是 O(m * klogk),也就是 O(m * (n/m)log(n/m)),继续简化 O(nlog(n/m))
4. m 趋近于 n 的时候其趋近于 O(n)

#### 是稳定排序
桶内排序方法是稳定排序的时候就是稳定的排序
#### 不是原地排序
需要用额外的空间来作为桶，因此不是原地排序，空间复杂度是 O(n + k), k 是桶的个数

#### 使用条件

1. 需要排序的数据需要很容易划分成 m 个桶，并且桶之间有着大小顺序
2. 每个桶中的数据分布要比较均匀

#### 适用情况

桶排序比较适合用在外部排序中。也就是数据存储在外部磁盘且数据量大，但内存有限无法将整个数据全部加载到内存

**需求描述：**

有10GB的订单数据，需按订单金额（假设金额都是正整数）进行排序，但内存有限，仅几百MB

**解决思路：**
- 扫描一遍文件，看订单金额所处数据范围，比如1元-10万元，那么就分100个桶。
- 第一个桶存储金额1-1000元之内的订单，第二个桶存1001-2000元之内的订单，依次类推。
- 每个桶对应一个文件，并按照金额范围的大小顺序编号命名（00，01，02，…，99）。
- 将100个小文件依次放入内存并用快排排序。
- 所有文件排好序后，只需按照文件编号从小到大依次读取每个小文件并写到大文件中即可。
- 
**注意点：**

若单个文件无法全部载入内存，则针对该文件继续按照前面的思路进行处理即可。

### 计数排序

#### 思路

计数其实与桶排序非常类似，只是桶的粒度不同。当要排序的n个数据所处范围并不大时，比如最大值为k，则分成k个桶，这时每个桶内的数据值都是相同的。

```
void counting_sort(int arr[], int n)
{
    if (n <= 1) return;
    
    // 获取最大值
    int max = arr[0];
    for (int i = 1; i < n; ++i) {
        if (max < arr[i]) {
            max = arr[i];
        }
    }
    
    // 申请 max + 1 个空间 初始化为 0，记录元素的出现次数
    int *counts = malloc(sizeof(int) * (max + 1));
    for (int i = 0; i <= max; ++i) {
        counts[i] = 0;
    }
    
    // 计算从 0 到 max 大小的这些元素出现的次数
    for (int i = 0; i < n; ++i) {
        int val = arr[i];
        counts[val]++;
    }
    
    // 累加出现次数，遍历过后每个位置都记录了该小于等于该值的出现次数
    for (int i = 1; i <= max; ++i) {
        counts[i] = counts[i] + counts[i - 1];
    }
    
    // 临时数组
    int *tmp = malloc(sizeof(int) * n);
    // 遍历原数组
    for (int i = n - 1; i >= 0 ; --i) {
        // 取到当前位置元素
        int num = arr[i];
        // 由于 counts[num] 记录就是小于等于 num 大小元素的出现次数，因此将其减一就能获取到排序完成之后该大小元素最后一个位置
        int index = counts[num] - 1;
        // 将该元素放到对应位置
        tmp[index] = num;
        // 由于上面 num 大小的元素有一个排好了顺序，这里将 counts 中 num 对应的次数减一
        counts[num]--;
    }
    
    // 将结果拷贝给原数组
    for (int i = 0; i < n; ++i) {
        arr[i] = tmp[i];
    }
    
    free(counts);
    free(tmp);
}
```

**代码实现**

1. 查找需要排序的数组中的最大值 max
2. 申请 max + 1 大小的数组 counts，用于记录每个大小的元素出现次数，全都初始化为 0
3. 遍历原数组，记录每个大小元素出现的次数
4. 累加每个元素出现的次数，比如 counts 中 k 这个位置记录了 **小于等于** k 大小元素出现的次数
5. 遍历原数组，由于 counts[num] 记录就是 **小于等于** num 大小元素的出现次数，因此将其减一就能获取到排序完成之后该大小元素最后一个位置
6. 将 num 放到 临时数组对应的位置
7. 放好一个 num 大小的元素后将 counts[num] 的值减去 1 
8. 将临时数组的元素拷贝到原数组

#### 使用条件
1. 只能用在数据范围不大的场景中，若数据范围k比要排序的数据n大很多，就不适合用计数排序；
2. 计数排序只能给非负整数排序，其他类型需要在不改变相对大小情况下，转换为非负整数；
3. 比如如果考试成绩精确到小数后一位，就需要将所有分数乘以10，转换为整数。

#### 时间复杂度
O(n + k), k 是数据的范围

#### 是稳定排序
取决于往临时数组 tmp 中添加数据的先后，上面代码中从原数组后面往前遍历，这时原数组中相同大小的元素靠后的放在临时数组 tmp 靠后的位置，这样就保证了计数排序是稳定的排序。如果此时是从前往后遍历就不是稳定的排序了，正好与原数组中的顺序相反

#### 不是原地排序
需要用额外的空间来作为桶，因此不是原地排序，空间复杂度是 O(n + k), k 是数据的范围

### 基数排序
#### 算法原理（以排序10万个手机号为例来说明）
1. 比较两个手机号码a，b的大小，如果在前面几位中a已经比b大了，那后面几位就不用看了。
2. 借助稳定排序算法的思想，可以先按照最后一位来排序手机号码，然后再按照倒数第二位来重新排序，以此类推，最后按照第一个位重新排序。
3. 经过11次排序后，手机号码就变为有序的了。
4. 每次排序有序数据范围较小，可以使用桶排序或计数排序来完成。
#### 使用条件
1. 要求数据可以分割独立的“位”来比较；
2. 位之间由递进关系，如果a数据的高位比b数据大，那么剩下的地位就不用比较了；
3. 每一位的数据范围不能太大，要可以用线性排序，否则基数排序的时间复杂度无法做到O(n)。

#### 时间复杂度
O(n * k), k 是数据的维度（比如上面的例子中就是手机号的位数 11）

#### 是稳定排序
是稳定排序，如果不是稳定排序就实现不了多维度的排序

#### 不是原地排序
需要用额外的空间来作为桶，因此不是原地排序，空间复杂度是 O(n + k), k 是数据的维度

### QA 对于一组包含大小写的字符进行排序，使小写的排在大写的前面。若字符中不仅有大小写还有数字的话就将数字放中间

用两个指针a、b：a指针从头开始往后遍历，遇到大写字母就停下，b从后往前遍历，遇到小写字母就停下，交换a、b指针对应的元素；重复如上过程，直到a、b指针相交。

对于小写字母放前面，数字放中间，大写字母放后面，可以先将数据分为小写字母和非小写字母两大类，进行如上交换后再在非小写字母区间内分为数字和大写字母做同样处理

## 14 排序优化

### 排序算法选择

- 虽然线性排序算法的时间复杂度比较低，但是适用场景比较特殊。所以对于通用排序函数不能选择线性排序
- 小规模数据排序，可以选择复杂度是 O(n^2) 的排序算法
- 大规模数据，O(nlogn) 的排序算法更为合适
- 归并排序由于空间复杂度是 O(n) 因此使用很少

### 快排优化

快排最坏情况复杂度是 O(n^2), 出现这样情况的原因是当数据本来有序或者接近有序的时候，如果每次分区都选择最后位置的数据作为枢轴，这种情况下时间复杂度就会退化为 O(n^2)。
因此对于**快排的优化主要在于合理选择分区点。最理想的情况是被分区点分开的两个分区中，数据的数量差不多。**

#### 三数取中
每次取枢轴值都在区间的头尾中间分别取值，以这三个数中间的值作为枢轴点
#### 随机
顾名思义，随机从区间中取枢轴点

#### 解决递归时的栈溢出

1. 限制递归深度。一旦递归过深，超过了我们事先设定的阈值，就停止递归
2. 是通过在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈的过程

### 通用排序函数实现技巧

1. 数据量不大时，可以采取用时间换空间的思路
2. 数据量大时，优化快排分区点的选择
3. 防止堆栈溢出，可以选择在堆上手动模拟调用栈解决
4. 在排序区间中，当元素个数小于某个常数是，可以考虑使用 O(n^2) 级别的插入排序
5. 用哨兵简化代码，每次排序都减少一次判断，尽可能把性能优化到极致

## 15 二分查找（上）

### 思想
- 二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。
- 每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半
- 直到找到要查找的元素，或者区间被缩小为 0 说明查找的元素不存在

### 二分查找时间复杂度

每查找一次之后，剩余需要查找的区间就会缩小一半，这时候在最坏情况下需要将查找区间缩小到 0。因此 n / (2^k) = 1, k = log2n,时间复杂度就是 O(logn).

对数时间复杂度 O(logn) 某些情况下比常数级 O（1）还要高效，因为用大 O 标记法表示时间复杂度的时候，会省略掉常数、系数和低阶，如果这些常数系数有可能是非常大的数值，这时候 O(logn) 将优于 O（1）。

### 代码实现

循环
```
int binarySearch(int arr[], int n, int item)
{
    int start = 0, end = n - 1;
    while (start <= end) {
        int middle = start + ((end - start) >> 1);
        if (arr[middle] > item) {
            end = middle - 1;
        } else if (arr[middle] < item) {
            start = middle + 1;
        } else {
            return middle;
        }
    }
    return -1;
}
```

递归
```
int binary(int arr[], int start, int end, int item)
{
    if (start > end) return -1;
    
    int middle = start + ((end - start) >> 1);
    int midVal = arr[middle];
    if (midVal > item) {
        return binary(arr, start, middle - 1, item);
    } else if (midVal < item) {
        return binary(arr, middle + 1, end, item);
    } else {
        return middle;
    }
}

int binarySearch_1(int arr[], int n, int item)
{
    return binary(arr, 0, n - 1, item);
}
```

#### 注意点
- 循环退出条件 start <= end
- middle 的取值 (start + end) / 2 在数值较大的时候可能出现溢出
- start end 的更新注意 +1  和 -1。如果直接写成 low=mid 或者 high=mid，就可能会发生死循环。比如，当 high=3，low=3 时，如果 a[3] 不等于 value，就会导致一直循环不退出。

### 使用场景
- 必须是顺序表中的数组，当时链表的时候复杂度会升高
- 必须是有序数据
- 数据量太小不适合二分查找
- 数据比较较为耗费性能的时候就需要使用二分查找
- 数据量太大也不适合二分查找
- 大部分情况下，用二分查找可以解决的问题，用散列表、二叉树都可以解决。但是不管是散列表还是二叉树，都会需要比较多的额外的内存空间，二分查找只需要一个数组，较为节省空间

### QA

#### 求一个数 x 的平方根”？要求精确到小数点后 6 位

利用二分查找 0 到 x 之间的数 mid ,直到 mid * mid - x < 1e-6

```
double sqrt(double x)
{
    double start = 0, end = x, middle = 0;
    while (fabs(end - start) >= 1e-6) {
        middle = start + ((end - start) / 2);
        if (middle * middle > x) {
            end = middle;
        } else if (middle * middle < x) {
            start = middle;
        } else {
            return middle;
        }
    }
    return middle;
}
```

#### 分析使用链表储存数据时二分查找的时间复杂度

使用数组实现二分查找的时候，由于数组具有根据下标随机访问时间复杂度为 O（1）的特性，因此其主要的费时操作就是不断的缩小查找区间，区间缩小多少次就执行了多少步操作，因此可以计算出其时间复杂度是 O(logn)

使用链表来实现二分查找的时候，由于链表访问某个位置的时间复杂度是 O(n), 因此在查找阶段需要进行的操作如下：
- 第一次查找中点，移动指针 n/2 次
- 第二次，移动 n/4 次
- 第三次，移动 n/8 次
- ......
- 第 k 次， 移动 n/(2^k) 次

这时候在由于比较这一操作相较于移动指针的操作来说是常数阶，因此可以忽略

由此可以看出这是一个等比公式，在最坏情况下首项是 n/(2^k) = 1 (这时候 k = log2n), 公比 是 2，数列的项数等于 k。因此根据等比数列求和公式可以得出 

- sum = (1 - 2^k) / (1 - 2)
- sum = 2^k - 1
- sum = 2^(log2n) - 1
- sum = n - 1

因此算法的时间复杂度就是 O(n), 与遍历查找相同。但由于需要进行额外的其他操作，因此其效率低于遍历查找。


## 16 二分查找（下）

### 变体-：查找第一个值等于给定值的元素

```
int _bsearch(int arr[], int n, int item)
{
    int start = 0, end = n - 1;
    while (start <= end) {
        int mid = start + (end - start) / 2;
        if (arr[mid] > item) {
            end = mid - 1;
        } else if (arr[mid] < item) {
            start = mid + 1;
        } else {
            if ((mid == 0) || (arr[mid - 1] != item )) {
                return mid;
            } else {
                end = mid - 1;
            }
        }
    }
    return -1;
}
```

思路：

1. 使用二分查找进行处理
2. arr[mid] 大于 或者 小于 要查找的 item 的时候与二分查找处理相同
3. arr[mid] 等于 item 的时候，说明 mid 的值就是要查找的值，但是由于其可能有多个这时候需要额外判断
   
   1. 如果 mid == 0 ，说明 mid 位于数组的首位，一定是要查找的
   2. mid - 1 位置的元素 不等于 要查找的值说明 mid 位置的元素就是第一个 目标值

### 变体二：查找最后一个值等于给定值的元素

```
int _bsearch(int arr[], int n, int item)
{
    int start = 0, end = n - 1;
    while (start <= end) {
        int mid = start + (end - start) / 2;
        if (arr[mid] > item) {
            end = mid - 1;
        } else if (arr[mid] < item) {
            start = mid + 1;
        } else {
            if ((mid == n - 1) || (arr[mid + 1] != item )) {
                return mid;
            } else {
                start = mid + 1;
            }
        }
    }
    return -1;
}
```

思路:与变体一基本相同，也是要判断 arr[mid] 等于 item 的情况

### 变体三：查找第一个大于等于给定值的元素

```
int _bsearch(int arr[], int n, int item)
{
    int start = 0, end = n - 1;
    while (start <= end) {
        int mid = start + (end - start) / 2;
        if (arr[mid] >= item) {
            if ((mid == 0) || (arr[mid - 1] < item )) {
                return mid;
            } else {
                end = mid - 1;
            }
        } else {
            start = mid + 1;
        }
    }
    return -1;
}
```

思路

1. 使用二分查找
2. 当 arr[mid] 小于 要查找的值，则 start = mid + 1
3. 当 arr[mid] 大于等于 要查找的值的时候
   
   1. 如果 mid == 0 说明，mid 就是数组首位，满足条件
   2. 如果 arr[mid - 1] 小于 要查找的值，说明 mid 位置的元素就是第一个大于等于给定值的元素
   3. 其他情况下说明 mid 位置的元素虽然大于目标元素但不是第一个，需要继续进行查找

### 变体四：查找第一个小于等于给定值的元素

```
int _bsearch(int arr[], int n, int item)
{
    int start = 0, end = n - 1;
    while (start <= end) {
        int mid = start + (end - start) / 2;
        if (arr[mid] <= item) {
            if ((mid == n - 1) || (arr[mid + 1] > item )) {
                return mid;
            } else {
                start = mid + 1;
            }
        } else {
            end = mid - 1;
        }
    }
    return -1;
}
```

与变体三的思路基本相同

### QA
#### 1. 如何快速定位 IP 归属地

如何快速定位出一个IP地址的归属地？

>[202.102.133.0, 202.102.133.255] 山东东营市 
[202.102.135.0, 202.102.136.255] 山东烟台 
[202.102.156.34, 202.102.157.255] 山东青岛 
[202.102.48.0, 202.102.48.255] 江苏宿迁 
[202.102.49.15, 202.102.51.251] 江苏泰州 
[202.102.56.0, 202.102.56.255] 江苏连云港

假设我们有 12 万条这样的 IP 区间与归属地的对应关系，如何快速定位出一个IP地址的归属地呢？

将所有的 IP 区间的开始位置转化为 32 位 的数，然后放到数组中进行排序。

这样以来问题就转换为查找这个数组中最后一个小于等于目标 IP 对应的数值 的问题
 
#### 2. 如果有序数组是一个循环有序数组，比如 4，5，6，1，2，3。针对这种情况，如何实现一个求“值等于给定值”的二分查找算法呢？


```
int _bsearch(int nums[], int n, int target)
{
    int left = 0,right = numsSize-1;
    while(left<=right){
        int mid = (left+right)/2;
        
        if(nums[mid]==target){
            //找到了，返回
            return mid;
        }
        
        //左半边是正常序列
        if(nums[left]<=nums[mid]){
            //target在这个序列
            if(target>=nums[left] && target<=nums[mid]){
                //分到左半边
                right = mid-1;
            }else{
                //分到右半边
                left = mid+1;
            }
        }else{
            //右半边是正常序列
            //target在这个序列
            if(target>=nums[mid] && target<=nums[right]){
                //分到右半边
                left = mid+1;
            }else{
                //分到左半边
                right = mid-1;
            }
        }
    }
    return -1;
}
```

## 17 跳表

### 定义
为一个值有序的链表建立多级索引，比如每2个节点提取一个节点到上一级，我们把抽出来的那一级叫做索引或索引层。其中down表示down指针，指向下一级节点。以此类推，对于节点数为n的链表，大约可以建立log2n-1级索引。像这种为链表建立多级索引的数据结构就称为跳表。

### 跳表的时间复杂度

#### 1.计算跳表的高度
如果链表有n个节点，每2个节点抽取抽出一个节点作为上一级索引的节点，那第1级索引的节点个数大约是n/2，第2级索引的节点个数大约是n/4，依次类推，第k级索引的节点个数就是n/(2^k)。

假设索引有h级别，最高级的索引有2个节点，则有n/(2^h)=2，得出h=log2n-1，包含原始链表这一层，整个跳表的高度就是log2n。

#### 2.计算跳表的时间复杂度

假设我们在跳表中查询某个数据的时候，如果每一层都遍历m个节点，那在跳表中查询一个数据的时间复杂度就是O(m*logn)。

那这个m是多少呢？假设我们要查找的数据是x，在第k级索引中，我们遍历到y节点之后，发现x大于y，小于后面的节点z，所以我们通过y的down指针，从第k级下降到第k-1级索引。在第k-1级索引中，y和z之间只有3个节点（包含y和z），所以，我们在k-1级索引中最多只需要遍历3个节点，以此类推，每一级索引都最多只需要遍历3个节点。所以m=3。

因此在跳表中查询某个数据的时间复杂度就是O(logn)。

### 跳表的空间复杂度

#### 1.计算索引的节点总数

如果链表有n个节点，每2个节点抽取抽出一个节点作为上一级索引的节点，那每一级索引的节点数分别为：n/2，n/4，n/8，…，8，4，2，等比数列求和n-1，所以跳表的空间复杂度为O(n)。

#### 2.如何优化时间复杂度

如果链表有n个节点，每3或5个节点抽取抽出一个节点作为上一级索引的节点，那每一级索引的节点数分别为（以3为例）：n/3，n/9，n/27，…，27，9，3，1，等比数列求和n/2，所以跳表的空间复杂度为O(n)，和每2个节点抽取一次相比，时间复杂度要低不少呢。

### 高效的动态插入和删除
跳表本质上就是链表，所以仅插作，插入和删除操时间复杂度就为O(1)，但在实际情况中，要插入或删除某个节点，需要先查找到指定位置，而这个查找操作比较费时，但在跳表中这个查找操作的时间复杂度是O(logn)，所以，跳表的插入和删除操作的是时间复杂度也是O(logn)。

### 跳表索引动态更新

当往跳表中插入数据的时候，可以选择同时将这个数据插入到部分索引层中，那么如何选择这个索引层呢？可以通过随机函数来决定将这个节点插入到哪几级索引中，比如随机函数生成了值K，那就可以把这个节点添加到第1级到第K级索引中。

