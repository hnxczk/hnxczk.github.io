{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[99],{511:function(a,t,r){\"use strict\";r.r(t);var _=r(0),v=Object(_.a)({},function(){var a=this,t=a.$createElement,r=a._self._c||t;return r(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":a.$parent.slotKey}},[r(\"h1\",{attrs:{id:\"散列函数\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#散列函数\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 散列函数\")]),a._v(\" \"),r(\"h1\",{attrs:{id:\"_21-哈希算法-上\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_21-哈希算法-上\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 21 哈希算法 | 上\")]),a._v(\" \"),r(\"h2\",{attrs:{id:\"定义\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#定义\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 定义\")]),a._v(\" \"),r(\"blockquote\",[r(\"p\",[a._v(\"将任意长度的二进制值映射为固定长度的二进制值串的规则称为\"),r(\"strong\",[a._v(\"哈希算法\")]),a._v(\", 映射之后得到的值就是\"),r(\"strong\",[a._v(\"哈希值\")])])]),a._v(\" \"),r(\"h2\",{attrs:{id:\"要求\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#要求\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 要求\")]),a._v(\" \"),r(\"ol\",[r(\"li\",[a._v(\"从哈希值不能反向推导出原始数据\")]),a._v(\" \"),r(\"li\",[a._v(\"对输入数据敏感，原始数据较小的修改也会造成哈希值的大不相同\")]),a._v(\" \"),r(\"li\",[a._v(\"散列冲突的概率要很小\")]),a._v(\" \"),r(\"li\",[a._v(\"算法的执行效率要尽快高效，针对长文本也能快速计算哈希值\")])]),a._v(\" \"),r(\"h2\",{attrs:{id:\"应用\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#应用\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 应用\")]),a._v(\" \"),r(\"h3\",{attrs:{id:\"安全\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#安全\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 安全\")]),a._v(\" \"),r(\"p\",[a._v(\"应用于安全领域主要是因为一下两点\")]),a._v(\" \"),r(\"ol\",[r(\"li\",[a._v(\"很难根据哈希值反向推导出原始数据\")]),a._v(\" \"),r(\"li\",[a._v(\"散列冲突的概率很小\")])]),a._v(\" \"),r(\"h4\",{attrs:{id:\"为什么无法避免哈希冲突\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#为什么无法避免哈希冲突\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 为什么无法避免哈希冲突\")]),a._v(\" \"),r(\"blockquote\",[r(\"p\",[a._v(\"鸽巢原理：如果有 10 个鸽笼要放 11 只鸽子， 这样可定会有 2 只鸽子放在同 1 个鸽笼里。\")])]),a._v(\" \"),r(\"p\",[a._v(\"对应于哈希函数来说（以 MD5 举例）\")]),a._v(\" \"),r(\"ul\",[r(\"li\",[a._v(\"哈希值是固定 128 位二进制串，最多表示 2^128 个数据\")]),a._v(\" \"),r(\"li\",[a._v(\"要进行哈希的数据是无穷的\")])]),a._v(\" \"),r(\"p\",[a._v(\"因此肯定会存在哈希冲突。但是出现的概率小于 1/2^128\")]),a._v(\" \"),r(\"h3\",{attrs:{id:\"唯一标识\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#唯一标识\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 唯一标识\")]),a._v(\" \"),r(\"p\",[a._v(\"检索图片的方式\")]),a._v(\" \"),r(\"ol\",[r(\"li\",[a._v(\"直接对比图片的二进制，速度太慢\")]),a._v(\" \"),r(\"li\",[a._v(\"根据图片的二进制计算哈希值，然后比较哈希值，对于较大的图片来说依然非常耗时\")]),a._v(\" \"),r(\"li\",[a._v(\"根据图片的二进制的信息摘要(比如在开头，中间，尾部各取 100 字节，然后计算哈希值)，能减少很多工作量\")])]),a._v(\" \"),r(\"h3\",{attrs:{id:\"数据校验\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#数据校验\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 数据校验\")]),a._v(\" \"),r(\"p\",[a._v(\"通过哈希算法对文件分别取哈希值保存到种子文件中，下载完成后根据相同的哈希算法计算哈希值，如果不同就说明数据不对\")]),a._v(\" \"),r(\"h3\",{attrs:{id:\"散列函数-2\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#散列函数-2\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 散列函数\")]),a._v(\" \"),r(\"p\",[a._v(\"散列函数对哈希冲突的要求要低很多，对于反向解密也不关心。更注重散列后的值能否平均分布，以及函数的效率\")]),a._v(\" \"),r(\"h2\",{attrs:{id:\"qa\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#qa\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" QA\")]),a._v(\" \"),r(\"h3\",{attrs:{id:\"如何存储用户的密码\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#如何存储用户的密码\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 如何存储用户的密码\")]),a._v(\" \"),r(\"ol\",[r(\"li\",[a._v(\"选择安全的加密算法\")]),a._v(\" \"),r(\"li\",[a._v(\"可以引入 salt ，通过对原始数据加盐增加密码的复杂度，增加破解难度\")]),a._v(\" \"),r(\"li\",[a._v(\"利用特殊的算法比如 PBKDF2WithHmacSHA1 ，这种算法如无论密码长度多少，它计算字符串hash时间都是固定或者足够慢的。这样就降低了硬件计算的速度，减少不同长度字符串计算哈希值所需时间不一样而泄漏字符串长度信息，进一步减少风险。\")])]),a._v(\" \"),r(\"h3\",{attrs:{id:\"区块链的加密方式\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#区块链的加密方式\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 区块链的加密方式\")]),a._v(\" \"),r(\"p\",[a._v(\"区块链是一块块区块组成的，每个区块分为两部分：区块头和区块体。\")]),a._v(\" \"),r(\"p\",[a._v(\"区块头保存着 自己区块体 和 上一个区块头 的哈希值。\")]),a._v(\" \"),r(\"p\",[a._v(\"因为这种链式关系和哈希值的唯一性，只要区块链上任意一个区块被修改过，后面所有区块保存的哈希值就不对了。\")]),a._v(\" \"),r(\"p\",[a._v(\"区块链使用的是 SHA256 哈希算法，计算哈希值非常耗时，如果要篡改一个区块，就必须重新计算该区块后面所有的区块的哈希值，短时间内几乎不可能做到。\")]),a._v(\" \"),r(\"h1\",{attrs:{id:\"_22-哈希算法-哈希算法在分布式系统中的应用\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_22-哈希算法-哈希算法在分布式系统中的应用\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 22 哈希算法 | 哈希算法在分布式系统中的应用\")]),a._v(\" \"),r(\"h2\",{attrs:{id:\"负载均衡\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#负载均衡\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 负载均衡\")]),a._v(\" \"),r(\"p\",[a._v(\"通过哈希算法，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。\")]),a._v(\" \"),r(\"h2\",{attrs:{id:\"数据分片\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#数据分片\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 数据分片\")]),a._v(\" \"),r(\"h3\",{attrs:{id:\"如何统计“搜索关键词”出现的次数？\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#如何统计“搜索关键词”出现的次数？\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 如何统计“搜索关键词”出现的次数？\")]),a._v(\" \"),r(\"h4\",{attrs:{id:\"需求描述\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#需求描述\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 需求描述\")]),a._v(\" \"),r(\"p\",[a._v(\"假如我们有1T的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，该怎么做呢？\")]),a._v(\" \"),r(\"h4\",{attrs:{id:\"问题分析\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#问题分析\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 问题分析\")]),a._v(\" \"),r(\"p\",[a._v(\"这个问题有两个难点，第一个是搜索的日子很大，没办法放到一台机器的内存中。第二个是只用一台机器来处理这么巨大的数据，处理时间会很长。\")]),a._v(\" \"),r(\"h4\",{attrs:{id:\"解决方案\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#解决方案\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 解决方案\")]),a._v(\" \"),r(\"p\",[a._v(\"先对数据进行分片，然后采用多台（比如n台）机器进行处理。具体做法：从搜索记录的日志文件中依次读取每个关键词，并通过哈希函数计算该关键词的哈希值，然后跟机器的台数n取模，最终得到值就是该关键词应该被分到的机器编号，这样相同的关键词一定会被分配到同一台机器上，数据分配完成后，由多台机器并行进行统计，最后合并起来就是最终结果。\")]),a._v(\" \"),r(\"p\",[a._v(\"实际上，这里的处理过程也是 MapReduce 的基本设计思想。\")]),a._v(\" \"),r(\"h3\",{attrs:{id:\"如何快速判断图片是否存在图库中？\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#如何快速判断图片是否存在图库中？\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 如何快速判断图片是否存在图库中？\")]),a._v(\" \"),r(\"h4\",{attrs:{id:\"需求描述-2\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#需求描述-2\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 需求描述\")]),a._v(\" \"),r(\"p\",[a._v(\"假设现在我们的图库中有1亿张图片，如何快速判断图片是否在图库中？基本方式是给每个图片去唯一表示（或者信息摘要），然后构建散列表。\")]),a._v(\" \"),r(\"h4\",{attrs:{id:\"问题分析-2\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#问题分析-2\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 问题分析\")]),a._v(\" \"),r(\"p\",[a._v(\"很显然，在单台机器上构建散列表示行不通的，因为单台机器的内存有限，而1亿张图片构建散列表远远超过了单台机器的内存上限。\")]),a._v(\" \"),r(\"h4\",{attrs:{id:\"解决方案-2\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#解决方案-2\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 解决方案\")]),a._v(\" \"),r(\"p\",[a._v(\"准备n台机器，让每台机器只维护一部分图片对应的散列表。我们每次从图库中读取一个图片，计算唯一标识，然后与机器个数n求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一表示和图片路径发往对应的机器构建散列表。\")]),a._v(\" \"),r(\"p\",[a._v(\"当我们要判断一个图片是否在图库中时，我们通过同样的哈希算法，计算这个图片的唯一表示，然后与机器个数n求余取模。假设得到的值是k，那就去编号为k的机器构建的散列表中查找。\")]),a._v(\" \"),r(\"p\",[a._v(\"如何估算给1亿张图片构建散列表大约需要多少台机器？\")]),a._v(\" \"),r(\"p\",[a._v(\"散列表中每个数据单元包含两个信息，哈希值和图片文件的路径。假设我们通过 MD5 来计算哈希值，那长度就是 128 比特，也就是 16 字节。文件路径长度的上限是 256 字节，我们可以假设平均长度是 128 字节。如果我们用链表法来解决冲突，那还需要存储指针，指针只占用 8 字节。所以，散列表中每个数据单元就占用 152 字节（这里只是估算，并不准确）。\")]),a._v(\" \"),r(\"p\",[a._v(\"假设一台机器的内存大小为 2GB，散列表的装载因子为 0.75，那一台机器可以给大约 1000 万（2GB*0.75/152）张图片构建散列表。所以，如果要对 1 亿张图片构建索引，需要大约十几台机器。在工程中，这种估算还是很重要的，能让我们事先对需要投入的资源、资金有个大概的了解，能更好地评估解决方案的可行性。\")]),a._v(\" \"),r(\"p\",[a._v(\"实际上，针对这种海量数据的处理问题，我们都可以采用多机分布式处理。借助这种分片的思路，可以突破单机内存、CPU 等资源的限制。\")]),a._v(\" \"),r(\"h2\",{attrs:{id:\"分布式存储\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#分布式存储\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 分布式存储\")]),a._v(\" \"),r(\"h3\",{attrs:{id:\"什么是分布式存储？\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#什么是分布式存储？\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 什么是分布式存储？\")]),a._v(\" \"),r(\"p\",[a._v(\"分布式存储就是将数据存储在多台机器上并提供高效的读取、写入支持。那如何决定将哪个数据放到哪个机器上呢？可以利用数据分片的思想，即通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号。\")]),a._v(\" \"),r(\"h3\",{attrs:{id:\"遇到的问题是什么？\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#遇到的问题是什么？\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 遇到的问题是什么？\")]),a._v(\" \"),r(\"p\",[a._v(\"如果数据持续增多，原来的机器数量已经不能满足需求，就需要增加机器，这时就麻烦了，因为所有的数据都需要重新哈希值进行再次分配。这就相当于，缓存中的数据一下子都失效了，所有的数据请求都会穿透缓存，直接去请求数据库。这样就可能发生雪崩效应，压垮数据库。\")]),a._v(\" \"),r(\"h3\",{attrs:{id:\"解决方案是什么？\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#解决方案是什么？\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 解决方案是什么？\")]),a._v(\" \"),r(\"ul\",[r(\"li\",[a._v(\"这时，需要一种方法，使得新加入一个机器后，并不需要做大量的数据搬移。那就是在分布式系统中应用非常广泛的一致性哈希算法。\")]),a._v(\" \"),r(\"li\",[a._v(\"一致性哈希算法的基本思想是什么呢？为了说清楚这个问题，我们假设有k个机器，数据的哈希值范围是[0-MAX]，我们将整个范围划分成m个小区间（m远大于k），每个机器复杂m/k个小区间。当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据量的均衡。\")])]),a._v(\" \"),r(\"h3\",{attrs:{id:\"一致性哈希算法栗子：\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#一致性哈希算法栗子：\",\"aria-hidden\":\"true\"}},[a._v(\"#\")]),a._v(\" 一致性哈希算法栗子：\")]),a._v(\" \"),r(\"blockquote\",[r(\"p\",[a._v(\"我们钟表有 60 分钟，从 0 开始到 59，共 60 个点。\\n现在我们将机器往这 60 个点分配，规则如下：\\nhash(ip) % 60。\")]),a._v(\" \"),r(\"p\",[a._v(\"假设有 3 台机器 A，B 和 C，分别被分配到了 14，37 和 46 这三个点上。\")]),a._v(\" \"),r(\"p\",[a._v(\"图片的分配规则类似：\\nhash(image_id) % 60。\\n现有 3 张图片 x， y， z，分别被分配到 5，30，50 这三个点。\")]),a._v(\" \"),r(\"p\",[a._v(\"很明示，图片都没被分配到机器的节点上，怎么办呢?在钟表上顺时钟往前寻找，第一台遇到的机器，就是它的归属。\")]),a._v(\" \"),r(\"p\",[a._v(\"现在很不凑巧，A B C 三台机器分别分配到 5，10，15 这三个点。这样对 A 是很不公平的吖，要负责存储绝大多数的图片，那这怎么办呢?我们社会主义核心价值观基本内容：和谐、平等、公正。为建设和谐社会努力奋斗！！\")]),a._v(\" \"),r(\"p\",[a._v(\"为了避免不必要的争端，我们引入“虚拟节点”，每台机器都可以拔一根汗毛，变成若干台，把虚拟节点分散到 60 个点上，归属“虚拟节点”的图片，均保存到它的真身。这样就能解决分配不均匀的问题。\")]),a._v(\" \"),r(\"p\",[a._v(\"应用时，将 60 替换下即可，如替换为 2的 32 次方。\")])])])},[],!1,null,null,null);t.default=v.exports}}]);","extractedComments":[]}